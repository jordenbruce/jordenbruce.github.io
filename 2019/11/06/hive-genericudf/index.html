<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="hadoop,hive,dw,database,sql,oozie,sqoop,architecture"><title>Hive自定义函数GenericUDF | JordenBruce</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hive自定义函数GenericUDF</h1><a id="logo" href="/.">JordenBruce</a><p class="description">A thousand miles begins with a single step.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hive自定义函数GenericUDF</h1><div class="post-meta">Nov 6, 2019<span> | </span><span class="category"><a href="/categories/Data-Warehouse/">Data Warehouse</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 910</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 4</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>编写 Apache Hive 用户自定义函数（UDF）有两个不同的接口：一个是非常简单的 UDF，上一篇已经介绍过了；还有一个是 GenericUDF，相对复杂点。两个 API 的区别是：如果函数的参数和返回都是基础数据类型，那么简单 API（UDF）可以胜任；但是，如果你想写一个函数用来操作内嵌数据结构，如 Map、List 和 Set，此时就需要去熟悉复杂 API（GenericUDF）。<br><a id="more"></a></p>
<h2 id="0x00-自定义-GenericUDF-开发"><a href="#0x00-自定义-GenericUDF-开发" class="headerlink" title="0x00 自定义 GenericUDF 开发"></a>0x00 自定义 GenericUDF 开发</h2><p>编写 GenericUDF 需要两个步骤：</p>
<ul>
<li>继承 <code>org.apache.hadoop.hive.ql.udf.generic.GenericUDF</code> 类；</li>
<li>重写 <code>initialize</code> ，<code>evaluate</code> ，<code>getDisplayString</code> 三个方法；</li>
</ul>
<p>每个方法有着不同的作用，参考如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// 这个方法只调用一次，并且在evaluate()方法之前调用。</span><br><span class="line">// 该方法接受的参数是一个ObjectInspectors数组，表示函数输入参数类型。</span><br><span class="line">// 1.检查接受正确的参数个数；</span><br><span class="line">// 2.检查接受正确的参数类型；</span><br><span class="line">// 3.定义返回值被序列化的一致类型。</span><br><span class="line">abstract ObjectInspector initialize(ObjectInspector[] arguments);</span><br><span class="line"></span><br><span class="line">// 这个方法类似UDF的evaluate()方法。它处理真实的参数，并返回最终结果。</span><br><span class="line">abstract Object evaluate(DeferredObject[] arguments);</span><br><span class="line"></span><br><span class="line">// 这个方法用于当实现的GenericUDF出错的时候，打印出提示信息。</span><br><span class="line">// 而提示信息就是你实现该方法最后返回的字符串。 </span><br><span class="line">abstract String getDisplayString(String[] children);</span><br></pre></td></tr></table></figure>
<p>其中有个 ObjectInspector 需要解释下，简单来说是帮助使用者访问需要序列化或者反序列化的对象，为数据类型提供一致性的访问接口。有关 ObjectInspector 更深入地理解，请参考 <a href="https://www.jianshu.com/p/5ea006282238" target="_blank" rel="noopener">Hive-ObjectInspector</a></p>
<h2 id="0x01-官方-ArrayGenericUDF-示例代码"><a href="#0x01-官方-ArrayGenericUDF-示例代码" class="headerlink" title="0x01 官方 ArrayGenericUDF 示例代码"></a>0x01 官方 ArrayGenericUDF 示例代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">package com.data.hive;</span><br><span class="line"></span><br><span class="line">import java.util.ArrayList;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hive.ql.udf.generic.GenericUDF;</span><br><span class="line">import org.apache.hadoop.hive.ql.udf.generic.GenericUDFUtils;</span><br><span class="line">import org.apache.hadoop.hive.ql.exec.Description;</span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDFArgumentException;</span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDFArgumentTypeException;</span><br><span class="line">import org.apache.hadoop.hive.ql.exec.UDFArgumentLengthException;</span><br><span class="line">import org.apache.hadoop.hive.ql.metadata.HiveException;</span><br><span class="line">import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;</span><br><span class="line">import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters;</span><br><span class="line">import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorConverters.Converter;</span><br><span class="line">import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;</span><br><span class="line">import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;</span><br><span class="line"></span><br><span class="line">@Description(</span><br><span class="line">        name = &quot;array&quot;,</span><br><span class="line">        value = &quot;_FUNC_(n0, n1...) - Creates an array with the given elements &quot;)</span><br><span class="line">public class ArrayGenericUDF extends GenericUDF &#123;</span><br><span class="line"></span><br><span class="line">    private transient Converter[] converters;</span><br><span class="line">    private transient ArrayList&lt;Object&gt; ret = new ArrayList&lt;Object&gt;();</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public ObjectInspector initialize(ObjectInspector[] arguments) throws UDFArgumentException &#123;</span><br><span class="line"></span><br><span class="line">        if (arguments.length &lt; 1) &#123;</span><br><span class="line">            throw new UDFArgumentLengthException(&quot;array() takes at least one parameter.&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        GenericUDFUtils.ReturnObjectInspectorResolver returnOIResolver = new GenericUDFUtils.ReturnObjectInspectorResolver(true);</span><br><span class="line"></span><br><span class="line">        for (int i = 0; i &lt; arguments.length; i++) &#123;</span><br><span class="line">            if (!returnOIResolver.update(arguments[i])) &#123;</span><br><span class="line">                throw new UDFArgumentTypeException(i, &quot;Argument type \&quot;&quot;</span><br><span class="line">                        + arguments[i].getTypeName()</span><br><span class="line">                        + &quot;\&quot; is different from preceding arguments. &quot;</span><br><span class="line">                        + &quot;Previous type was \&quot;&quot; + arguments[i - 1].getTypeName() + &quot;\&quot;&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        converters = new Converter[arguments.length];</span><br><span class="line"></span><br><span class="line">        ObjectInspector returnOI =</span><br><span class="line">                returnOIResolver.get(PrimitiveObjectInspectorFactory.javaStringObjectInspector);</span><br><span class="line">        for (int i = 0; i &lt; arguments.length; i++) &#123;</span><br><span class="line">            converters[i] = ObjectInspectorConverters.getConverter(arguments[i], returnOI);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return ObjectInspectorFactory.getStandardListObjectInspector(returnOI);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public Object evaluate(DeferredObject[] arguments) throws HiveException &#123;</span><br><span class="line">        ret.clear();</span><br><span class="line">        for (int i = 0; i &lt; arguments.length; i++) &#123;</span><br><span class="line">            ret.add(converters[i].convert(arguments[i].get()));</span><br><span class="line">        &#125;</span><br><span class="line">        return ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String getDisplayString(String[] children) &#123;</span><br><span class="line">        return getStandardDisplayString(&quot;array&quot;, children, &quot;,&quot;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="0x02-代码走读"><a href="#0x02-代码走读" class="headerlink" title="0x02 代码走读"></a>0x02 代码走读</h2><p>方法的调用关系如下：</p>
<ol>
<li><p>ArrayGenericUDF 用默认的构造器来初始化；</p>
</li>
<li><p>initialize() 被调用，传入函数参数的 ObjectInspector[] 数组；<br>2.1. 检查传入的参数个数与每个参数的数据类型是正确的；<br>2.2. 保存 converters (ObjectInspector) 用以供 evaluate() 使用；<br>2.3. 返回 ListObjectInspector，让 Hive 能够读取该函数的返回结果；</p>
</li>
<li><p>对于查询中的每一行，evaluate() 方法都会被调用，并传入该行的指定列；<br>3.1. 利用 initialize() 方法中存储的 converters (ObjectInspector) 来抽取出正确的值；<br>3.2. 执行处理逻辑然后用 initialize() 返回的 ListObjectInspector 来序列化返回值；</p>
</li>
</ol>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/SerDe" target="_blank" rel="noopener">SerDe</a><br><a href="https://blog.matthewrathbone.com/2013/08/10/guide-to-writing-hive-udfs.html" target="_blank" rel="noopener">Hadoop Hive UDF Tutorial - Extending Hive with Custom Functions</a><br><a href="https://www.jianshu.com/p/5ea006282238" target="_blank" rel="noopener">Hive-ObjectInspector</a></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>JordenBruce</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/11/06/hive-genericudf/">https://jordenbruce.com/2019/11/06/hive-genericudf/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jordenbruce.com/2019/11/06/hive-genericudf/" data-id="ck2rki6eg000n6wn3t5t5eawi" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACKUlEQVR42u3aQXLCMAwFUO5/6XTbGWj4kgLT2M8rBgjxy0LIkh6PeB2/1vM7yafnv/zXXS5eGBgYt2Ucp6vKeN7E81W9+755NBgYGBswklB4flWy3RyT7w0DAwMjufEkgCbvY2BgYMwZ+WE1TzcxMDAweofYXsDNk8UvncUxMDBuyMir7t9//ZH+BgYGxq0YR3ElqV61MXmMFwYGxtqMPMAl7cm8cJY/gsJ+MDAwFmVMjqw9drUAF8EwMDCWZuTl+NEN4oJaNfV88b+BgYGxHKPXvOwNh/WiZXL0xcDA2I2RXNxrGFQPsXl5DgMDYx9G73U14E6GMD7YX8XAwPjHjPMm4ue+3yvkvTlsY2BgLMo431BShstLZtUDc6FIh4GBsRmjWqzvrTxMRw8FAwNjA0Y+eNEbpMgbn6OZEQwMjEUZSZibJHB5wS4/xEaPEgMDYzlGsq2koJ9stDp+MQqyGBgYSzB6wxb55vJmQL6TF/fCwMBYmtELl72iW6/BUBi/wMDA2IYxL+jnoTZPQJM0FAMDYwdGNdhVRyiq6eaoL4qBgbEBoxf4qsfaJFksgDEwMBZlTNK1eUGt9wcQJYUYGBgLMeZ5V17EnwxVTH4NAwNjDcb3g+w5Jj/QYmBg7Ma4quk4qYNNEkcMDAyMaiJYRVbD+iOP4hgYGFsyJqMYedsgH93AwMDYh5EX1HqtzWqKWQZjYGAszciPjknR/6pS2lUjGhgYGDdn/AC5XRkGwjyA0AAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/hive/">hive</a></div><div class="post-nav"><a class="pre" href="/2019/11/07/hive-genericudtf/">Hive自定义函数GenericUDTF</a><a class="next" href="/2019/11/03/hive-udf/">Hive自定义函数UDF</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '24d554575e1f11313fa9',
  clientSecret: '8de4e32b66c3386a10942a3c5e29cf09b8954c26',
  repo: 'jordenbruce.github.io',
  owner: 'jordenbruce',
  admin: ['jordenbruce'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="https://jordenbruce.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Warehouse/">Data Warehouse</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/modeling/" style="font-size: 15px;">modeling</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/mapreduce/" style="font-size: 15px;">mapreduce</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/workflow/" style="font-size: 15px;">workflow</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/11/09/hive-genericudaf/">Hive自定义函数GenericUDAF</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/07/hive-genericudtf/">Hive自定义函数GenericUDTF</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/06/hive-genericudf/">Hive自定义函数GenericUDF</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/03/hive-udf/">Hive自定义函数UDF</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/03/hive-jdbc-client/">Java通过JDBC连接Hive</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/02/hive-architecture/">Hive体系结构</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/19/hadoop-hdfs/">HDFS架构原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/16/hadoop-yarn/">YARN技术原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/13/hadoop-mapreduce/">MapReduce执行过程详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/12/junior-manual/">数据仓库的初级手册</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://hao.199it.com" title="大数据导航" target="_blank">大数据导航</a><ul></ul><a href="https://www.infoq.cn" title="InfoQ" target="_blank">InfoQ</a><ul></ul><a href="https://ppsteven.github.io" title="软微9133" target="_blank">软微9133</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">JordenBruce.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>