<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="hadoop,hive,dw,database,sql,oozie,sqoop,architecture"><title>HQL内存溢出的参数调优 | JordenBruce</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">HQL内存溢出的参数调优</h1><a id="logo" href="/.">JordenBruce</a><p class="description">A thousand miles begins with a single step.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">HQL内存溢出的参数调优</h1><div class="post-meta">Feb 25, 2019<span> | </span><span class="category"><a href="/categories/Hive/">Hive</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.1k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 8</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>我们在使用Hive进行ETL开发的过程中，关注更多的是使用HQL语言来准确地表达业务逻辑，而很少考虑到Hive对HQL语句的执行情况。当你辛辛苦苦地码完，将HQL语句扔给Hive去执行时，就有可能出现各种各样的报错，而其中一种比较常见的错误就是内存溢出（OOM，out of memory），通俗地讲就是内存不够。<br><a id="more"></a></p>
<h2 id="1-写在前面"><a href="#1-写在前面" class="headerlink" title="1. 写在前面"></a>1. 写在前面</h2><p>本文采用的软件版本如下：</p>
<ul>
<li>hive-2.0.1</li>
<li>hadoop-2.7.2</li>
</ul>
<p>hive使用MapReduce执行引擎，hadoop使用Yarn进行资源调度。</p>
<p>下文将从客户端提交HQL语句开始，Hive生成物理执行计划、Yarn资源分配、MapReduce执行，到执行结束，三个重点过程进行阐述，先理论再参数，希望OOM参数调优的问题得到收敛。</p>
<h2 id="2-Hive生成物理执行计划"><a href="#2-Hive生成物理执行计划" class="headerlink" title="2. Hive生成物理执行计划"></a>2. Hive生成物理执行计划</h2><p>先给出官网上关于Hive架构的经典流程图：</p>
<p><img src="https://i.loli.net/2019/02/24/5c72ad01e0c56.png" alt="Hive架构"></p>
<p>从这张图中，我们只需要明白一点即可：客户端提交的HQL语句，在Hive端的最终输出是物理执行计划，或者说是Job的有向无环图（a DAG of stages）。主要包括三种操作：</p>
<ul>
<li>MapReduce作业（a map/reduce job）</li>
<li>元数据操作（a metadata operation）</li>
<li>HDFS操作（an operation on HDFS）</li>
</ul>
<p>需要注意的是：这个过程主要是Hive优化器的执行，没有相关参数去控制内存的使用。当然，对于某些HQL语句适当地设置一些参数，可以得到更优的物理执行计划。比如常见的Map Join参数<code>hive.auto.convert.join</code>等。</p>
<h2 id="3-Yarn资源分配"><a href="#3-Yarn资源分配" class="headerlink" title="3. Yarn资源分配"></a>3. Yarn资源分配</h2><p>YARN是对Mapreduce V1重构得到的，有时候也成为MapReduce V2。由Hive生成物理执行计划，其中的MapReduce作业提交给Yarn来执行，详细的执行过程如下：</p>
<p><img src="https://i.loli.net/2019/02/24/5c72b4b3294ea.jpg" alt="MapReduce在Yarn下执行过程"></p>
<p>从上图可以看出，Yarn（以Container方式分配）控制着NodeManager、ApplicationMaster、Map和Reduce的内存使用，相关的内存参数有：</p>
<table>
<thead>
<tr>
<th>重要级别</th>
<th>参数名</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>中</td>
<td>yarn.nodemanager.resource.memory-mb</td>
<td>8192</td>
</tr>
<tr>
<td>中</td>
<td>yarn.scheduler.minimum-allocation-mb</td>
<td>1024</td>
</tr>
<tr>
<td>中</td>
<td>yarn.scheduler.maximum-allocation-mb</td>
<td>8192</td>
</tr>
<tr>
<td>中</td>
<td>yarn.scheduler.increment-allocation-mb</td>
<td>1024</td>
</tr>
<tr>
<td>高</td>
<td>yarn.app.mapreduce.am.resource.mb</td>
<td>1536</td>
</tr>
<tr>
<td>中</td>
<td>yarn.app.mapreduce.am.command-opts</td>
<td>-Xmx1024m</td>
</tr>
<tr>
<td>低</td>
<td>yarn.app.mapreduce.am.admin-command-opts</td>
<td></td>
</tr>
<tr>
<td>中</td>
<td>yarn.nodemanager.vmem-pmem-ratio</td>
<td>2.1</td>
</tr>
<tr>
<td>低</td>
<td>yarn.nodemanager.pmem-check-enabled</td>
<td>true</td>
</tr>
<tr>
<td>低</td>
<td>yarn.nodemanager.vmem-check-enabled</td>
<td>true</td>
</tr>
<tr>
<td>高</td>
<td>mapreduce.reduce.memory.mb</td>
<td>1024</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.reduce.java.opts</td>
<td></td>
</tr>
<tr>
<td>高</td>
<td>mapreduce.map.memory.mb</td>
<td>1024</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.map.java.opts</td>
</tr>
</tbody>
</table>
<h3 id="3-1-基础"><a href="#3-1-基础" class="headerlink" title="3.1 基础"></a>3.1 基础</h3><ul>
<li>NodeManager可用于分配的最大内存是yarn.nodemanager.resource.memory-mb；</li>
<li>Yarn的ResourceManger（简称RM）通过逻辑上的队列分配内存等资源给application，默认情况下RM允许最大AM申请Container资源为8192MB(“yarn.scheduler.maximum-allocation-mb“)，默认情况下的最小分配资源为1024M(“yarn.scheduler.minimum-allocation-mb“)，如果参数中需要的资源在此范围之外，在任务submit的时候会被直接拒绝掉；</li>
<li>AM只能以增量 (“yarn.scheduler.minimum-allocation-mb”) + (“yarn.scheduler.increment-allocation-mb”) 规整每个task需要的内存，并且申请的内存只能在（”yarn.scheduler.minimum-allocation-mb“）和(“yarn.scheduler.maximum-allocation-mb“) 的范围内向RM申请资源；</li>
<li>每个Map任务或Reduce任务分配的内存为mapreduce.reduce.memory.mb或mapreduce.map.memory.mb；</li>
</ul>
<h3 id="3-2-mapreduce-map-java-opts和mapreduce-map-memory-mb区别"><a href="#3-2-mapreduce-map-java-opts和mapreduce-map-memory-mb区别" class="headerlink" title="3.2 mapreduce.map.java.opts和mapreduce.map.memory.mb区别"></a>3.2 mapreduce.map.java.opts和mapreduce.map.memory.mb区别</h3><p>JVM进程跑在container中，mapreduce.map.java.opts能够通过Xmx设置JVM最大的heap的使用，一般设置为0.75倍的mapreduce.map.memory.mb ，因为需要为java code，非JVM内存使用等预留些空间；mapreduce.reduce.java.opts和mapreduce.reduce.memory.mb同理。</p>
<h3 id="3-3-虚拟内存"><a href="#3-3-虚拟内存" class="headerlink" title="3.3 虚拟内存"></a>3.3 虚拟内存</h3><p>默认的(“yarn.nodemanager.vmem-pmem-ratio“)设置为2.1，意味则map container或者reduce container分配的虚拟内存超过2.1倍的(“mapreduce.reduce.memory.mb“)或(“mapreduce.map.memory.mb“)就会被NM给KILL掉，如果 (“mapreduce.map.memory.mb”) 被设置为1536M那么总的虚拟内存为2.1*1536=3225.6MB</p>
<h3 id="3-4-内存检查"><a href="#3-4-内存检查" class="headerlink" title="3.4 内存检查"></a>3.4 内存检查</h3><p>如果虚拟内存检查被打开（yarn.nodemanager.vmem-check-enabled默认情况下为true），然后YARN将把抽取出来的容器及其子进程的VSIZE加起来和容器最大允许使用的虚拟内存进行比较。最大允许使用的虚拟内存是容器最大可使用的物理内存乘以 yarn.nodemanager.vmem-pmem-ratio（默认值是2.1）。所以，如果你的YARN容器配置的最大可使用物理内存为2GB，然后我们乘以 2.1 得到的就是容器最大可用的虚拟内存 4.2G 。</p>
<p>如果物理内存检查被打开（yarn.nodemanager.pmem-check-enabled默认情况为true），然后YARN将把抽取出来的容器及其子进程的RSS加起来和容器最大允许使用的物理内存进行比较。</p>
<p>如果物理内存或者虚拟内存其中一个的使用大于最大允许使用的，YARN将会被这个容器杀掉。</p>
<h3 id="3-5-参数全局图"><a href="#3-5-参数全局图" class="headerlink" title="3.5 参数全局图"></a>3.5 参数全局图</h3><p>参数多不要慌，下面来张图梳理下：</p>
<p><img src="https://i.loli.net/2019/02/25/5c72c07905cf3.jpg" alt="Yarn内存参数"></p>
<h2 id="4-MapReduce执行"><a href="#4-MapReduce执行" class="headerlink" title="4. MapReduce执行"></a>4. MapReduce执行</h2><p>MapReduce作业的重点是Shuffle过程，还是老套路，先给出官网上关于这个过程的经典流程图：</p>
<p><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/pNFrlaAqE9YU.png" alt="Shuffle过程"></p>
<p>当Map任务或Reduce任务以Container方式申请到相应的内存资源后，就进入了实际的执行过程中，其中涉及的参数有：</p>
<table>
<thead>
<tr>
<th>重要级别</th>
<th>参数名</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>高</td>
<td>mapreduce.job.maps</td>
<td>2</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.input.fileinputformat.split.minsize</td>
<td>1</td>
</tr>
<tr>
<td>中</td>
<td>dfs.blocksize</td>
<td>134217728</td>
</tr>
<tr>
<td>高</td>
<td>mapreduce.job.reduces</td>
<td>1</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.task.io.sort.mb</td>
<td>100</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.map.sort.spill.percent</td>
<td>0.80</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.task.io.sort.factor</td>
<td>10</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.map.output.compress</td>
<td>false</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.map.output.compress.codec</td>
<td>org.apache.hadoop.io.compress.DefaultCodec</td>
</tr>
<tr>
<td>低</td>
<td>mapreduce.job.reduce.slowstart.completedmaps</td>
<td>0.05</td>
</tr>
<tr>
<td>中</td>
<td>mapreduce.reduce.shuffle.parallelcopies</td>
<td>5</td>
</tr>
<tr>
<td>高</td>
<td>mapreduce.reduce.shuffle.input.buffer.percent</td>
<td>0.70</td>
</tr>
</tbody>
</table>
<p>为了更好地理解每个参数作用的阶段，建议先阅读 <a href="https://jordenbruce.com/2019/02/19/hadoop-shuffle/">MapReduce之Shuffle过程详解</a>。</p>
<h3 id="4-1-Map任务"><a href="#4-1-Map任务" class="headerlink" title="4.1 Map任务"></a>4.1 Map任务</h3><p>（1）split分片：split是在逻辑上对输入数据进行的分片，并不会在磁盘上将其切分成分片进行存储。每个split都作为一个独立单位分配给一个map task去处理。决定split分片大小的参数有：</p>
<ul>
<li>mapreduce.job.maps</li>
<li>mapreduce.input.fileinputformat.split.minsize</li>
<li>dfs.blocksize (会话级别不可设置)</li>
</ul>
<p>（2）内存缓冲区：经过map处理后的键值对，不会立马写入磁盘，而是暂时保存在内存中的MapOutputBuffe内部的环形数据缓冲区，设置缓冲区大小的参数有：</p>
<ul>
<li>mapreduce.task.io.sort.mb</li>
<li>mapreduce.map.sort.spill.percent</li>
</ul>
<p>（3）压缩：map端在写磁盘的时候采用压缩的方式将map的输出结果进行压缩是一个减少网络开销很有效的方法。其实，在Hadoop中早已为我们提供了一些压缩算法的实现，直接配置参数即可。</p>
<ul>
<li>mapreduce.map.output.compress</li>
<li>mapreduce.map.output.compress.codec</li>
</ul>
<h3 id="4-2-Reduce任务"><a href="#4-2-Reduce任务" class="headerlink" title="4.2 Reduce任务"></a>4.2 Reduce任务</h3><p>（1）文件拷贝：默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的 <code>mapreduce.job.reduce.slowstart.completedmaps</code> (默认为0.05) 后，ApplicationMaster便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动 <code>mapred.reduce.parallel.copies</code> (默认为5) 个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上。</p>
<p>（2）内存缓冲区：这个内存缓冲区大小的控制就不像map那样可以通过 <code>mapreduce.task.io.sort.mb</code> 来设定了，而是通过另外一个参数来设置：<code>mapred.job.shuffle.input.buffer.percent</code>（default 0.7）， 这个参数其实是一个百分比，意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × maxHeap of reduce task。</p>
<h2 id="5-HQL语句的日志输出"><a href="#5-HQL语句的日志输出" class="headerlink" title="5. HQL语句的日志输出"></a>5. HQL语句的日志输出</h2><p>经过漫长的理论铺垫，终于要到解决问题的时候了，HQL语句的内存溢出主要从日志分析开始。</p>
<ul>
<li>HQL语句的执行过程中，有哪些日志输出呢？分别存放在什么地方？如何分析出有用信息？</li>
<li>内存溢出包括哪几类？典型日志有哪些？调优什么参数可以解决？</li>
<li>小文件太多是如何产生的？调优什么参数可以合并小文件？</li>
</ul>
<p>等等一系列有关问题，且听下回分解。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/Design" target="_blank" rel="noopener">Hive Architecture Overview</a><br><a href="https://segmentfault.com/a/1190000003777237" target="_blank" rel="noopener">Yarn下Mapreduce的内存参数理解</a><br><a href="https://jordenbruce.com/2019/02/19/hadoop-shuffle/">MapReduce之Shuffle过程详解</a><br><a href="https://blog.csdn.net/lazythinker/article/details/75497774" target="_blank" rel="noopener">HIVE参数调优（汇总）</a><br><a href="https://blog.csdn.net/aijiudu/article/details/72353510" target="_blank" rel="noopener">MapReduce过程详解及其性能优化</a><br><a href="https://my.oschina.net/OttoWu/blog/816049" target="_blank" rel="noopener">hadoop fair scheduler 的坑</a></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>JordenBruce</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/02/25/hive-oom/">https://jordenbruce.com/2019/02/25/hive-oom/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jordenbruce.com/2019/02/25/hive-oom/" data-id="ck0uou3zu001hksn3xppxxtus" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACJ0lEQVR42u3aS27DMAxF0ex/0y7QUQetch9FBzV1NQqM2NHxgOFHrxde1/f66/PPK+vr6++Qu7aWDBkyHsu4lmvN4JtLeXxvMmTIOIfBH0diHdkQD+jrvcmQIUNGLQhygAwZMmTcF3BJ0CQpXforMmTIOJlBAij/Ad44S4N1Qy0uQ4aMBzL2BwP3ff7ofEOGDBn/knGFi4wta9/hQfaXu2TIkDGaQcpRfp2nbnzAyVNSGTJkTGXUAiIfXu4crSCvT4YMGScwai2wNIw2/CcsnyNDhowTGGTEmDboeVst5b3JcGXIkDGOsf8O7jtgESSjMmTIGM1IC8u0lb8/DCB3yZAh4xxGrcl132iThGMZMmScwOAhMk3OulI9VOjKkCHjGAafHvBwmT4zPfYhQ4aMcxjpACBl7NTT6KXIkCFjNIOMKmtNt/QAR1fBLEOGjHMYtUTwChcvYoNjZDJkyBjHSFtptRYbTxZryagMGTJmM3ZqQJ7ApQliekWGDBmzGV3b5Q01HkyD/ciQIeMARtfoMU3seIvtTZNOhgwZoxlpg56PKjn7hddW2JUhQ8ZjGb2tfH6QgqePKAGVIUPGaEYa7NLGXDoc5SNSfkRDhgwZMxhpIbpz/KIrfYwTRBkyZIxg8MMTO1uPZ6q8hJYhQ4YMHCLToNkwwpQhQ4aM8EgE+eFbYDJkyDiAwYcB/C6eaNYafMVaXIYMGQ9kNBSQTa23WqksQ4aM0Ywvg+HwLgKaTm4AAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/OOM/">OOM</a></div><div class="post-nav"><a class="pre" href="/2019/03/04/hive-partition/">Hive分区表</a><a class="next" href="/2019/02/21/hadoop-yarn/">YARN架构详解</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '24d554575e1f11313fa9',
  clientSecret: '8de4e32b66c3386a10942a3c5e29cf09b8954c26',
  repo: 'jordenbruce.github.io',
  owner: 'jordenbruce',
  admin: ['jordenbruce'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="https://jordenbruce.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Warehouse/">Data Warehouse</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo/">Hexo</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hive/">Hive</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/hadoop/">hadoop</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/思维游戏/">思维游戏</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Partition/" style="font-size: 15px;">Partition</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/MapReduce/" style="font-size: 15px;">MapReduce</a> <a href="/tags/UDF/" style="font-size: 15px;">UDF</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/YARN/" style="font-size: 15px;">YARN</a> <a href="/tags/OOM/" style="font-size: 15px;">OOM</a> <a href="/tags/策略思维/" style="font-size: 15px;">策略思维</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/09/22/hdfs-cli/">hdfs命令行的常用操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/20/hadoop-cli/">hadoop命令行的常用操作</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/sqoop-install/">手动搭建Sqoop开发环境</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/hive-install/">手动搭建Hive开发环境</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/hadoop-install/">手动搭建Hadoop分布式运行环境</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/hadoop-build/">编译Hadoop源码包</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/09/15/hadoop-release/">Hadoop发行版的选取</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/14/strategy001/">裁员还是减薪</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/14/hive-udf/">Hive自定义函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/04/hive-partition/">Hive分区表</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://hao.199it.com" title="大数据导航" target="_blank">大数据导航</a><ul></ul><a href="https://www.infoq.cn" title="InfoQ" target="_blank">InfoQ</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">JordenBruce.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>