<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="hadoop,hive,dw,database,sql,oozie,sqoop,architecture"><title>MapReduce执行过程详解 | JordenBruce</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MapReduce执行过程详解</h1><a id="logo" href="/.">JordenBruce</a><p class="description">A thousand miles begins with a single step.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MapReduce执行过程详解</h1><div class="post-meta">Oct 13, 2019<span> | </span><span class="category"><a href="/categories/Hadoop/">Hadoop</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.3k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 4</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。<br><a id="more"></a></p>
<h2 id="0x00-分析MapReduce执行过程"><a href="#0x00-分析MapReduce执行过程" class="headerlink" title="0x00 分析MapReduce执行过程"></a>0x00 分析MapReduce执行过程</h2><p>MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。整个流程如图：</p>
<p><img src="https://i.loli.net/2019/10/12/jotATrBqyIzV5cY.png" alt="MapReduce执行过程"></p>
<h2 id="0x01-Mapper任务的执行过程详解"><a href="#0x01-Mapper任务的执行过程详解" class="headerlink" title="0x01 Mapper任务的执行过程详解"></a>0x01 Mapper任务的执行过程详解</h2><p><strong>每个Mapper任务是一个java进程</strong>，它会读取HDFS中的文件，解析成很多的键值对，经过我们覆盖的map方法处理后，转换为很多的键值对再输出。整个Mapper任务的处理过程又可以分为以下几个阶段，如图所示：</p>
<p><img src="https://i.loli.net/2019/10/12/6jbSxLJQNqls4FP.png" alt="Mapper执行过程"></p>
<p>在上图中，把Mapper任务的运行过程分为六个阶段。</p>
<ol>
<li><p>第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。默认情况下，输入片(InputSplit)的大小与数据块(Block)的大小是相同的。如果数据块(Block)的大小是默认值64MB，输入文件有两个，一个是32MB，一个是72MB。那么小的文件是一个输入片，大文件会分为两个数据块，那么是两个输入片。一共产生三个输入片。每一个输入片由一个Mapper进程处理。这里的三个输入片，会有三个Mapper进程处理。</p>
</li>
<li><p>第二阶段是对输入片中的记录按照一定的规则解析成键值对。有个默认规则是把每一行文本内容解析成键值对。“键”是每一行的起始位置(单位是字节)，“值”是本行的文本内容。</p>
</li>
<li><p>第三阶段是调用Mapper类中的map方法。第二阶段中解析出来的每一个键值对，调用一次map方法。如果有1000个键值对，就会调用1000次map方法。每一次调用map方法会输出零个或者多个键值对。</p>
</li>
<li><p>第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。比较是基于键进行的。比如我们的键表示省份(如北京、上海、山东等)，那么就可以按照不同省份进行分区，同一个省份的键值对划分到一个区中。默认是只有一个区。分区的数量就是Reducer任务运行的数量。默认只有一个Reducer任务。</p>
</li>
<li><p>第五阶段是对每个分区中的键值对进行排序。首先，按照键进行排序，对于键相同的键值对，按照值进行排序。比如三个键值对&lt;2,2&gt;、&lt;1,3&gt;、&lt;2,1&gt;，键和值分别是整数。那么排序后的结果是&lt;1,3&gt;、&lt;2,1&gt;、&lt;2,2&gt;。如果有第六阶段，那么进入第六阶段；如果没有，直接输出到本地的linux文件中。</p>
</li>
<li><p>第六阶段是对数据进行归约处理，也就是reduce处理。键相等的键值对会调用一次reduce方法。经过这一阶段，数据量会减少。归约后的数据输出到本地的linxu文件中。本阶段默认是没有的，需要用户自己增加这一阶段的代码。</p>
</li>
</ol>
<h2 id="0x02-Reducer任务的执行过程详解"><a href="#0x02-Reducer任务的执行过程详解" class="headerlink" title="0x02 Reducer任务的执行过程详解"></a>0x02 Reducer任务的执行过程详解</h2><p><strong>每个Reducer任务是一个java进程</strong>。Reducer任务接收Mapper任务的输出，归约处理后写入到HDFS中，可以分为如下图所示的几个阶段。</p>
<p><img src="https://i.loli.net/2019/10/12/HXhC2wvUQLKdV4e.png" alt="Reducer执行过程"></p>
<ol>
<li><p>第一阶段是Reducer任务会主动从Mapper任务复制其输出的键值对。Mapper任务可能会有很多，因此Reducer会复制多个Mapper的输出。</p>
</li>
<li><p>第二阶段是把复制到Reducer本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</p>
</li>
<li><p>第三阶段是对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法，每次调用会产生零个或者多个键值对。最后把这些输出的键值对写入到HDFS文件中。</p>
</li>
</ol>
<p>在整个MapReduce程序的开发过程中，我们最大的工作量是覆盖map函数和覆盖reduce函数。</p>
<h2 id="0x03-键值对的编号"><a href="#0x03-键值对的编号" class="headerlink" title="0x03 键值对的编号"></a>0x03 键值对的编号</h2><p>在对Mapper任务、Reducer任务的分析过程中，会看到很多阶段都出现了键值对，读者容易混淆，所以这里对键值对进行编号，方便大家理解键值对的变化情况，如下图所示。</p>
<p><img src="https://i.loli.net/2019/10/12/q6Y9Sl5ofQCW7LJ.png" alt="键值对"></p>
<p>在上图中，对于Mapper任务输入的键值对，定义为key1和value1。在map方法中处理后，输出的键值对，定义为key2和value2。reduce方法接收key2和value2，处理后，输出key3和value3。在下文讨论键值对时，可能把key1和value1简写为&lt;k1,v1&gt;，key2和value2简写为&lt;k2,v2&gt;，key3和value3简写为&lt;k3,v3&gt;。</p>
<h2 id="转载说明"><a href="#转载说明" class="headerlink" title="转载说明"></a>转载说明</h2><p><a href="https://my.oschina.net/itblog/blog/275294" target="_blank" rel="noopener">Hadoop MapReduce执行过程详解（带hadoop例子）</a><br><a href="http://matt33.com/2016/03/02/hadoop-shuffle/" target="_blank" rel="noopener">MapReduce之Shuffle过程详述</a></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>JordenBruce</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/10/13/hadoop-mapreduce/">https://jordenbruce.com/2019/10/13/hadoop-mapreduce/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jordenbruce.com/2019/10/13/hadoop-mapreduce/" data-id="ck264zvk00015o0n3mu1x0xqb" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACHElEQVR42u3aQY7DMAgF0N7/0pkDVI0+4IwU+3k1qtqEt2EA8/nE5/o635//+n7y5OqvmgcDA+O1jOv23DO+Q0nekrw9jw0DA+McRpIKk7SYJM0k0Dw2DAwMjOTF1e/nCR0DAwOjx7j/JPlV3vpiYGBgVBPiZMSWP/PxXhwDA+OFjHzq/v9/P3K/gYGB8SrGVTz3qbNaCCZPi6LCwMDYmrH2ArKaUicJFwMD4zRGteKaXB701sJGNS8GBsYWjNyaD/2rqxULFj4wMDAOYDRbx6VNbDXVYmBgnMPI1ynyFYr5UkWPjYGBsSsjH/r3Uup8DBcN1zAwMDZl5AVZdRmrehU6aWUxMDD2ZlRTcF7MrUrZ+cIHBgbG3owk0Gq51uyki63yJxdjYGC8lpEn1t6IbYIs7FFgYGAcyVhb/CU1adIe/4wWAwPjAEZ1BJb3xOXU2TsYGBgHMKoJ97lLgt6qBwYGxt6MXjbr/bb3/ObNBgYGxnaMyaJqHnRehub/Bn5eD2BgYGzKqK5H9AJNRnXNNTUMDIwDGJPCbtLQzoeDGBgYezOu4slb0PwJOTUqCjEwMLZj9JJdL6D5AG7Z7BADA+OFjOoVYx5WL3U2l8wwMDAOYPQSX/W6MV+2KKd+DAwMjCD0QnKMi8JCVYuBgYERFHC9y8gEHJEwMDAOYOTrWZNGN0/cD/biGBgYL2TkrePa1+dD/3nri4GB8VrGH/nl2xm4/rd8AAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/mapreduce/">mapreduce</a></div><div class="post-nav"><a class="pre" href="/2019/10/16/hadoop-yarn/">YARN技术原理</a><a class="next" href="/2019/10/12/junior-manual/">数据仓库的初级手册</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '24d554575e1f11313fa9',
  clientSecret: '8de4e32b66c3386a10942a3c5e29cf09b8954c26',
  repo: 'jordenbruce.github.io',
  owner: 'jordenbruce',
  admin: ['jordenbruce'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="https://jordenbruce.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Warehouse/">Data Warehouse</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/modeling/" style="font-size: 15px;">modeling</a> <a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/mapreduce/" style="font-size: 15px;">mapreduce</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/workflow/" style="font-size: 15px;">workflow</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/10/19/hadoop-hdfs/">HDFS架构原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/16/hadoop-yarn/">YARN技术原理</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/13/hadoop-mapreduce/">MapReduce执行过程详解</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/12/junior-manual/">数据仓库的初级手册</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/10/workflow/">常见的任务调度系统</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/09/growth-model/">简化版的增长模型</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/08/sqoop-cli/">Sqoop命令行的导入与导出</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/05/hql-function-string/">HiveQL的字符串函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/05/hql-function-date/">HiveQL的日期函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/10/05/hql-function-math/">HiveQL的数学函数</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://hao.199it.com" title="大数据导航" target="_blank">大数据导航</a><ul></ul><a href="https://www.infoq.cn" title="InfoQ" target="_blank">InfoQ</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">JordenBruce.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>