<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="hadoop,hive,dw,database,sql,oozie,sqoop,architecture"><title>hadoop命令行的常用操作 | JordenBruce</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">hadoop命令行的常用操作</h1><a id="logo" href="/.">JordenBruce</a><p class="description">A thousand miles begins with a single step.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">hadoop命令行的常用操作</h1><div class="post-meta">Sep 20, 2019<span> | </span><span class="category"><a href="/categories/Data-Warehouse/">Data Warehouse</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 886</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i><span class="post-count"> 3</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>编译并安装Hadoop分布式运行环境之后，第一个要用到的命令行就是hadoop。需要注意的是：每个发行版的命令行语法有些不一样，可以通过<code>hadoop -help</code>进行查看。<br><a id="more"></a></p>
<h2 id="0x00-hadoop命令行的语法"><a href="#0x00-hadoop命令行的语法" class="headerlink" title="0x00 hadoop命令行的语法"></a>0x00 hadoop命令行的语法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  where COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              print the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use &quot;yarn jar&quot; to launch</span><br><span class="line">                             YARN applications, not this command.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  daemonlog            get/set the log level for each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br></pre></td></tr></table></figure>
<p>每个命令的具体含义如下：</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>version</td>
<td>打印hadoop版本</td>
</tr>
<tr>
<td>checknative</td>
<td>检测native库和压缩库的可用性</td>
</tr>
<tr>
<td>fs</td>
<td>hdfs命令行的客户端</td>
</tr>
<tr>
<td>jar</td>
<td>运行jar包里的mapreduce程序(推荐使用yarn jar)</td>
</tr>
<tr>
<td>distcp</td>
<td>用于大规模集群内部和集群之间拷贝的工具</td>
</tr>
<tr>
<td>archive</td>
<td>将小文件进行hadoop存档</td>
</tr>
<tr>
<td>classpath</td>
<td>打印类路径</td>
</tr>
<tr>
<td>credential</td>
<td>管理凭证供应商</td>
</tr>
<tr>
<td>daemonlog</td>
<td>获取/设置每个守护程序的日志级别</td>
</tr>
<tr>
<td>trace</td>
<td>查看和修改Hadoop跟踪设置</td>
</tr>
</tbody>
</table>
<p>其中，最常用的有 fs jar archive distcp 。</p>
<h2 id="0x01-hadoop-fs"><a href="#0x01-hadoop-fs" class="headerlink" title="0x01 hadoop fs"></a>0x01 hadoop fs</h2><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs <args>的形式。所有的的FS shell命令使用URI路径作为参数。URI格式是scheme://authority/path。对HDFS文件系统，scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如/parent/child可以表示成hdfs://namenode:namenodeport/parent/child，或者更简单的/parent/child（假设你配置文件中的默认值是namenode:namenodeport）。大多数FS Shell命令的行为和对应的Unix Shell命令类似。</args></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /</span><br><span class="line">hadoop fs -mkdir /external</span><br><span class="line">hadoop fs -touchz /external/readme</span><br><span class="line">hadoop fs -put $&#123;HADOOP_HOME&#125;README.txt /external</span><br><span class="line">hadoop fs -du -h /external</span><br><span class="line">hadoop fs -find /external readme</span><br><span class="line">hadoop fs -tail /external/README.txt</span><br><span class="line">hadoop fs -rm /external/readme</span><br></pre></td></tr></table></figure>
<p>还有很多命令，这里就不一一演示了。</p>
<h2 id="0x02-hadoop-archive"><a href="#0x02-hadoop-archive" class="headerlink" title="0x02 hadoop archive"></a>0x02 hadoop archive</h2><p>Hadoop archives是特殊的档案格式。一个Hadoop archive对应一个文件系统目录。Hadoop archive的扩展名是*.har。Hadoop archive包含元数据（形式是_index和_masterindx）和数据（part-*）文件。_index文件包含了档案中的文件的文件名和位置信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archiveName readme.har -p / external /archive</span><br><span class="line">hadoop fs -ls -R har:///archive/readme.har</span><br><span class="line">hadoop fs -cat har:///archive/readme.har/external/README.txt</span><br></pre></td></tr></table></figure>
<h2 id="0x03-hadoop-distcp"><a href="#0x03-hadoop-distcp" class="headerlink" title="0x03 hadoop distcp"></a>0x03 hadoop distcp</h2><p>DistCp（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。它使用Map/Reduce实现文件分发，错误处理和恢复，以及报告生成。它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝。由于使用了Map/Reduce方法，这个工具在语义和执行上都会有特殊的地方。</p>
<p>DistCp最常用在集群之间的拷贝：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop distcp hdfs://nn1:8020/foo/bar hdfs://nn2:8020/bar/foo</span><br></pre></td></tr></table></figure>
<p>这条命令会把nn1集群的/foo/bar目录下的所有文件或目录名展开并存储到一个临时文件中，这些文件内容的拷贝工作被分配给多个map任务，然后每个TaskTracker分别执行从nn1到nn2的拷贝操作。注意DistCp使用绝对路径进行操作。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p><a href="https://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-common/CommandsManual.html" target="_blank" rel="noopener">Hadoop Commands Guide</a><br><a href="https://jordenbruce.com/2019/10/12/dw-junior-manual/">数据仓库的初级手册</a></p>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>JordenBruce</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/2019/09/20/hadoop-cli/">https://jordenbruce.com/2019/09/20/hadoop-cli/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a class="article-share-link" data-url="https://jordenbruce.com/2019/09/20/hadoop-cli/" data-id="ck9qzbhf600057on3p19ise2n" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACJ0lEQVR42u3aS46DQAxF0ex/09ULiCjus0lLuG6NoohADgPLv88Hn/V1+PX8Gn7/4pEhQ8ZrGWt79g/ow/hzb16lDBkyDmBcPfjq8/5XJNSSgE7+mwwZMmTsGftryPX8PjJkyJDBGbzE7SSCMmTIkFErYnkA5c21NFg/UIvLkCHjhQzedf//zz+Zb8iQIeNVjBUewkvD5WofGTJkzGbwAMd5aZKHClQyfpAhQ8ZQRn8kkBa6tbWwG5gMGTJGM8gCBH9Aek06AECtPRkyZIxj8BulCxM87NZC7WVuK0OGjHGMNGXkYTQtdFMAGmTKkCFjBGMfIknKWJszdkYLQeEqQ4aMEYxOO5630mqjzWLiKEOGjAMYpN2fNvc7A0vyImTIkHEm49mmPx9e8rT1JtuVIUPGOAa/HQ+anVSvWDbLkCFjKKOzVNovRMkLQo05GTJkjGbwAWQnBUyHl8UjQ4aMoYzakkSnJZcGdNSekyFDxmgGT79qiV26zFEbPMiQIeMEBg+1naZYbeUiYMuQIeMwRvp9uhyW3u2BhTAZMmSMYKRtsnibI7ySDz5lyJAxm7HCU1unSP90XDbLkCFjNKMf7NJytxPcHxh/ypAh47UMXmr2i9i0MRcsc8iQIeMABhln8jZc55tWKStDhgwZeDmjH0D5oEKGDBkyajUxSRnTUhkVsTJkyBjNqK1n8ZQxHQbw8liGDBknMHjpWCtuyZ/43QuSIUPGyxl/+JyJh9YEkkkAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/hadoop/">hadoop</a></div><div class="post-nav"><a class="pre" href="/2019/09/22/hdfs-cli/">hdfs命令行的常用操作</a><a class="next" href="/2019/09/15/sqoop-install/">手动搭建Sqoop开发环境</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '24d554575e1f11313fa9',
  clientSecret: '8de4e32b66c3386a10942a3c5e29cf09b8954c26',
  repo: 'jordenbruce.github.io',
  owner: 'jordenbruce',
  admin: ['jordenbruce'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="https://jordenbruce.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Data-Warehouse/">Data Warehouse</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hadoop/">Hadoop</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/hadoop/" style="font-size: 15px;">hadoop</a> <a href="/tags/hive/" style="font-size: 15px;">hive</a> <a href="/tags/sqoop/" style="font-size: 15px;">sqoop</a> <a href="/tags/modeling/" style="font-size: 15px;">modeling</a> <a href="/tags/workflow/" style="font-size: 15px;">workflow</a> <a href="/tags/hdfs/" style="font-size: 15px;">hdfs</a> <a href="/tags/mapreduce/" style="font-size: 15px;">mapreduce</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2020/02/29/hive-partition-bucket/">【翻译】Hive中的分区和桶</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/21/hive-config-property/">常用的Hive用户配置属性</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/20/idea-maven-udf/">IDEA用Maven开发UDF的最佳实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/20/hive-fileformat-compress/">Hive存储格式与压缩</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/12/hive-metastore/">Hive元数据的解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/12/hql-select-groupby/">HiveQL的Select语句之GroupBy子句</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/09/hql-function-analytic/">HiveQL的分析函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/08/hql-function-window/">HiveQL的窗口函数</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/17/hadoop-yarn-scheduler/">Yarn三种Scheduler调度器</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/11/16/hive-skew-group/">Hive数据倾斜之GroupBy</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://hao.199it.com" title="大数据导航" target="_blank">大数据导航</a><ul></ul><a href="https://www.infoq.cn" title="InfoQ" target="_blank">InfoQ</a><ul></ul><a href="https://ppsteven.github.io" title="软微9133" target="_blank">软微9133</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">JordenBruce.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>