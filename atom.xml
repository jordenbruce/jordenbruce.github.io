<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JordenBruce</title>
  
  <subtitle>A thousand miles begins with a single step.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jordenbruce.com/"/>
  <updated>2019-02-19T15:34:45.805Z</updated>
  <id>https://jordenbruce.com/</id>
  
  <author>
    <name>JordenBruce</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MapReduce之Shuffle过程详解</title>
    <link href="https://jordenbruce.com/2019/02/19/hadoop-shuffle/"/>
    <id>https://jordenbruce.com/2019/02/19/hadoop-shuffle/</id>
    <published>2019-02-19T13:44:20.000Z</published>
    <updated>2019-02-19T15:34:45.805Z</updated>
    
    <content type="html"><![CDATA[<p>MapReduce计算模型一般包括两个重要的阶段：Map是映射，负责数据的过滤分发，将原始数据转化为键值对；Reduce是规约，将具有相同key值的value进行处理后再输出新的键值对作为最终结果。为了让Reduce可以并行处理Map的结果，必须对Map的输出进行一定的排序与分割，然后再交给对应的Reduce，而这个将Map输出进行进一步整理并交给Reduce的过程就是Shuffle。<br><a id="more"></a></p><h2 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h2><p>Shuffle过程是MapReduce的核心，也被称为奇迹发生的地方。要想理解MapReduce，Shuffle是必须要了解的。这里先给出官网上关于这个过程的经典流程图：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/pNFrlaAqE9YU.png" alt="Shuffle过程"><br>上图是把MapReduce过程分为两个部分，而实际上从两边的Map和Reduce到中间的那一大块都属于Shuffle过程，也就是说，Shuffle过程有一部分是在Map端，有一部分是在Reduce端，下文也将会分两部分来介绍Shuffle过程。<br>对于Hadoop集群，当我们在运行作业时，大部分的情况下，map task与reduce task的执行是分布在不同的节点上的，因此，很多情况下，reduce执行时需要跨节点去拉取其他节点上的map task结果，这样造成了集群内部的网络资源消耗很严重，而且在节点的内部，相比于内存，磁盘IO对性能的影响是非常严重的。如果集群中运行的作业有很多，那么task的执行对于集群内部网络的资源消费非常大。因此，我们对于MapRedue作业Shuffle过程的期望是：</p><ul><li>完整地从map task端拉取数据到Reduce端；</li><li>在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗；</li><li>减少磁盘IO对task执行的影响。</li></ul><h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>在进行海量数据处理时，外存文件数据I/O访问会成为一个制约系统性能的瓶颈，因此，Hadoop的Map过程实现的一个重要原则就是：计算靠近数据，这里主要指两个方面：</p><ol><li>代码靠近数据：<ul><li>原则：本地化数据处理（locality），即一个计算节点尽可能处理本地磁盘上所存储的数据；</li><li>尽量选择数据所在DataNode启动Map任务；</li><li>这样可以减少数据通信，提高计算效率；</li></ul></li><li>数据靠近代码：<ul><li>当本地没有数据处理时，尽可能从同一机架或最近其他节点传输数据进行处理（host选择算法）。</li></ul></li></ol><p>下面，我们分块去介绍Hadoop的Map过程，map的经典流程图如下：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/Hc0RIDhvW7CU.jpg" alt="map-shuffle"></p><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><ol><li>map task只读取split分片，split与block（hdfs的最小存储单位，默认为64MB）可能是一对一也能是一对多，但是对于一个split只会对应一个文件的一个block或多个block，不允许一个split对应多个文件的多个block；</li><li>这里切分和输入数据的时会涉及到InputFormat的文件切分算法和host选择算法。</li></ol><p>文件切分算法，主要用于确定InputSplit的个数以及每个InputSplit对应的数据段。FileInputFormat以文件为单位切分生成InputSplit，对于每个文件，由以下三个属性值决定其对应的InputSplit的个数：</p><ul><li>goalSize：它是根据用户期望的InputSplit数目计算出来的，即totalSize/numSplits。其中，totalSize为文件的总大小；numSplits为用户设定的Map Task个数，默认情况下是1；</li><li>minSize：InputSplit的最小值，由配置参数mapred.min.split.size确定，默认是1；</li><li>blockSize：文件在hdfs中存储的block大小，不同文件可能不同，默认是64MB。</li></ul><p>这三个参数共同决定InputSplit的最终大小，计算方法如下：<br><code>splitSize = max{minSize, min{gogalSize,blockSize}}</code></p><p>细节请参考《<a href="https://blog.csdn.net/xingliang_li/article/details/53285447" target="_blank" rel="noopener">FileInputFormat类中split切分算法和host选择算法介绍</a>》</p><h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><ul><li>作用：将map的结果发送到相应的reduce端，总的partition的数目等于reducer的数量。</li><li>实现功能：<ol><li>map输出的是key/value对，决定于当前的mapper的part交给哪个reduce的方法是：mapreduce提供的Partitioner接口，对key进行hash后，再以reducetask数量取模，然后到指定的job上（HashPartitioner，可以通过job.setPartitionerClass(MyPartition.class)自定义）。</li><li>然后将数据写入到内存缓冲区，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。key/value对以及Partition的结果都会被写入缓冲区。在写入之前，key与value值都会被序列化成字节数组。</li></ol></li><li>要求：负载均衡，效率；</li></ul><h3 id="spill（溢写）：sort-amp-combiner"><a href="#spill（溢写）：sort-amp-combiner" class="headerlink" title="spill（溢写）：sort &amp; combiner"></a>spill（溢写）：sort &amp; combiner</h3><ul><li>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（quick sort）；</li><li>注意：<ol><li>这个spill是由另外单独的线程来完成，不影响往缓冲区写map结果的线程；</li><li>内存缓冲区默认大小限制为100MB，它有个溢写比例（spill.percent），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，maptask的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做环形缓冲区（两个指针的方向不会变，下面会详述）；</li><li>在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次排序操作，先按&lt;key,value,partition&gt;中的partition分区号排序，然后再按key排序，这个就是sort操作，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</li></ol></li></ul><p>combine：执行combine操作要求开发者必须在程序中设置了combine（程序中通过job.setCombinerClass(myCombine.class)自定义combine操作）。</p><ul><li>程序中有两个阶段可能会执行combine操作：<br>map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作（前提是作业中设置了这个操作）；<br>如果map输出比较大，溢出文件个数大于3（此值可以通过属性min.num.spills.for.combine配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作；</li><li>combine主要是把形如&lt;aa,1&gt;,&lt;aa,2&gt;这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到&lt;aa,3&gt;这样的结果。</li><li>注意事项：不是每种作业都可以做combine操作的，只有满足以下条件才可以：<ol><li>reduce的输入输出类型都一样，因为combine本质上就是reduce操作；</li><li>计算逻辑上，combine操作后不会影响计算结果，像求和就不会影响；</li></ol></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MapReduce计算模型一般包括两个重要的阶段：Map是映射，负责数据的过滤分发，将原始数据转化为键值对；Reduce是规约，将具有相同key值的value进行处理后再输出新的键值对作为最终结果。为了让Reduce可以并行处理Map的结果，必须对Map的输出进行一定的排序与分割，然后再交给对应的Reduce，而这个将Map输出进行进一步整理并交给Reduce的过程就是Shuffle。&lt;br&gt;
    
    </summary>
    
    
      <category term="MapReduce" scheme="https://jordenbruce.com/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce执行过程详解</title>
    <link href="https://jordenbruce.com/2019/02/17/hadoop-mapreduce/"/>
    <id>https://jordenbruce.com/2019/02/17/hadoop-mapreduce/</id>
    <published>2019-02-17T14:57:51.000Z</published>
    <updated>2019-02-18T13:47:30.710Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分析MapReduce执行过程"><a href="#分析MapReduce执行过程" class="headerlink" title="分析MapReduce执行过程"></a>分析MapReduce执行过程</h2><p>MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。整个流程如图：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/ttzqIIqCPiXv.png" alt="MapReduce执行过程"></p><h3 id="Mapper任务的执行过程详解"><a href="#Mapper任务的执行过程详解" class="headerlink" title="Mapper任务的执行过程详解"></a>Mapper任务的执行过程详解</h3><p><strong>每个Mapper任务是一个java进程</strong>，它会读取HDFS中的文件，解析成很多的键值对，经过我们覆盖的map方法处理后，转换为很多的键值对再输出。整个Mapper任务的处理过程又可以分为以下几个阶段，如图所示：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/cTWHrBBqmvhM.png" alt="Mapper执行过程"></p><p>在上图中，把Mapper任务的运行过程分为六个阶段。</p><ol><li><p>第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。默认情况下，输入片(InputSplit)的大小与数据块(Block)的大小是相同的。如果数据块(Block)的大小是默认值64MB，输入文件有两个，一个是32MB，一个是72MB。那么小的文件是一个输入片，大文件会分为两个数据块，那么是两个输入片。一共产生三个输入片。每一个输入片由一个Mapper进程处理。这里的三个输入片，会有三个Mapper进程处理。</p></li><li><p>第二阶段是对输入片中的记录按照一定的规则解析成键值对。有个默认规则是把每一行文本内容解析成键值对。“键”是每一行的起始位置(单位是字节)，“值”是本行的文本内容。</p></li><li><p>第三阶段是调用Mapper类中的map方法。第二阶段中解析出来的每一个键值对，调用一次map方法。如果有1000个键值对，就会调用1000次map方法。每一次调用map方法会输出零个或者多个键值对。</p></li><li><p>第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。比较是基于键进行的。比如我们的键表示省份(如北京、上海、山东等)，那么就可以按照不同省份进行分区，同一个省份的键值对划分到一个区中。默认是只有一个区。分区的数量就是Reducer任务运行的数量。默认只有一个Reducer任务。</p></li><li><p>第五阶段是对每个分区中的键值对进行排序。首先，按照键进行排序，对于键相同的键值对，按照值进行排序。比如三个键值对&lt;2,2&gt;、&lt;1,3&gt;、&lt;2,1&gt;，键和值分别是整数。那么排序后的结果是&lt;1,3&gt;、&lt;2,1&gt;、&lt;2,2&gt;。如果有第六阶段，那么进入第六阶段；如果没有，直接输出到本地的linux文件中。</p></li><li><p>第六阶段是对数据进行归约处理，也就是reduce处理。键相等的键值对会调用一次reduce方法。经过这一阶段，数据量会减少。归约后的数据输出到本地的linxu文件中。本阶段默认是没有的，需要用户自己增加这一阶段的代码。</p></li></ol><h3 id="Reducer任务的执行过程详解"><a href="#Reducer任务的执行过程详解" class="headerlink" title="Reducer任务的执行过程详解"></a>Reducer任务的执行过程详解</h3><p><strong>每个Reducer任务是一个java进程</strong>。Reducer任务接收Mapper任务的输出，归约处理后写入到HDFS中，可以分为如下图所示的几个阶段。<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/UPvIszDbzRJW.png" alt="Reducer执行过程"></p><ol><li><p>第一阶段是Reducer任务会主动从Mapper任务复制其输出的键值对。Mapper任务可能会有很多，因此Reducer会复制多个Mapper的输出。</p></li><li><p>第二阶段是把复制到Reducer本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</p></li><li><p>第三阶段是对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法，每次调用会产生零个或者多个键值对。最后把这些输出的键值对写入到HDFS文件中。</p></li></ol><p>在整个MapReduce程序的开发过程中，我们最大的工作量是覆盖map函数和覆盖reduce函数。</p><h3 id="键值对的编号"><a href="#键值对的编号" class="headerlink" title="键值对的编号"></a>键值对的编号</h3><p>在对Mapper任务、Reducer任务的分析过程中，会看到很多阶段都出现了键值对，读者容易混淆，所以这里对键值对进行编号，方便大家理解键值对的变化情况，如下图所示。<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/QXkSATq7bUWL.png" alt="键值对"></p><p>在上图中，对于Mapper任务输入的键值对，定义为key1和value1。在map方法中处理后，输出的键值对，定义为key2和value2。reduce方法接收key2和value2，处理后，输出key3和value3。在下文讨论键值对时，可能把key1和value1简写为&lt;k1,v1&gt;，key2和value2简写为&lt;k2,v2&gt;，key3和value3简写为&lt;k3,v3&gt;。</p><p>以上内容来自：<a href="https://my.oschina.net/itblog/blog/275294" target="_blank" rel="noopener">Hadoop MapReduce执行过程详解（带hadoop例子）</a></p>]]></content>
    
    <summary type="html">
    
      MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。
    
    </summary>
    
    
      <category term="MapReduce" scheme="https://jordenbruce.com/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://jordenbruce.com/2019/02/13/hello-world/"/>
    <id>https://jordenbruce.com/2019/02/13/hello-world/</id>
    <published>2019-02-13T14:23:16.089Z</published>
    <updated>2019-02-17T13:05:34.745Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="Hexo" scheme="https://jordenbruce.com/categories/Hexo/"/>
    
    
      <category term="Hexo" scheme="https://jordenbruce.com/tags/Hexo/"/>
    
  </entry>
  
</feed>
