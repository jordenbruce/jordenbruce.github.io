<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>JordenBruce</title>
  
  <subtitle>A thousand miles begins with a single step.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://jordenbruce.com/"/>
  <updated>2019-09-23T14:03:23.502Z</updated>
  <id>https://jordenbruce.com/</id>
  
  <author>
    <name>JordenBruce</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>HiveQL的Table常用操作</title>
    <link href="https://jordenbruce.com/2019/09/23/hql-table/"/>
    <id>https://jordenbruce.com/2019/09/23/hql-table/</id>
    <published>2019-09-23T00:28:31.000Z</published>
    <updated>2019-09-23T14:03:23.502Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Hive数据仓库软件有助于读取，写入和管理驻留在分布式存储中并使用SQL语法查询的大型数据集。而Table是Hive组织数据存储的主要数据单元，是一种结构化存储，用二维表结构来表示。<br><a id="more"></a></p><h2 id="0x00-create-table"><a href="#0x00-create-table" class="headerlink" title="0x00 create table"></a>0x00 create table</h2><p>经常使用的表有：内部表(managed table)，外部表(external table)，分区表(partitioned table)，临时表(temporary table)等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">--1. managed table</span><br><span class="line">create table if not exists default.managed_user (</span><br><span class="line">     kid       bigint  comment &apos;主键&apos;</span><br><span class="line">    ,user_id   string  comment &apos;用户编号&apos;</span><br><span class="line">    ,user_name string  comment &apos;用户名称&apos;</span><br><span class="line">)</span><br><span class="line">comment &apos;内部用户表&apos;</span><br><span class="line">stored as parquet</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">--2. external table</span><br><span class="line">create external table if not exists default.external_user (</span><br><span class="line">     kid       bigint  comment &apos;主键&apos;</span><br><span class="line">    ,user_id   string  comment &apos;用户编号&apos;</span><br><span class="line">    ,user_name string  comment &apos;用户名称&apos;</span><br><span class="line">)</span><br><span class="line">comment &apos;外部用户表&apos;</span><br><span class="line">stored as textfile</span><br><span class="line">location &apos;/external/user&apos;</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">--3. partitioned table</span><br><span class="line">create table if not exists default.partitioned_user (</span><br><span class="line">     kid       bigint  comment &apos;主键&apos;</span><br><span class="line">    ,user_id   string  comment &apos;用户编号&apos;</span><br><span class="line">    ,user_name string  comment &apos;用户名称&apos;</span><br><span class="line">)</span><br><span class="line">comment &apos;分区用户表&apos;</span><br><span class="line">partitioned by (</span><br><span class="line">    dt string comment &apos;日期分区&apos;</span><br><span class="line">)</span><br><span class="line">stored as parquet</span><br><span class="line">;</span><br><span class="line"></span><br><span class="line">--4. temporary table</span><br><span class="line">create temporary table if not exists default.temporary_user </span><br><span class="line">like default.managed_user</span><br><span class="line">;</span><br><span class="line">create temporary table if not exists default.temporary_user as </span><br><span class="line">select kid, user_id from default.partitioned_user where dt = &apos;2019-09-22&apos;</span><br><span class="line">;</span><br></pre></td></tr></table></figure><h2 id="0x01-alter-table"><a href="#0x01-alter-table" class="headerlink" title="0x01 alter table"></a>0x01 alter table</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">alter table default.external_user rename to default.external_user_ds;</span><br><span class="line"></span><br><span class="line">alter table default.managed_user set tblproperties(&quot;skip.header.line.count&quot;=&quot;1&quot;);</span><br><span class="line"></span><br><span class="line">alter table default.managed_user add columns (reg_date string comment &apos;注册日期&apos;);</span><br><span class="line">alter table default.partitioned_user add columns (reg_date string comment &apos;注册日期&apos;) cascade;</span><br></pre></td></tr></table></figure><h2 id="0x02-describe-table-amp-show-table"><a href="#0x02-describe-table-amp-show-table" class="headerlink" title="0x02 describe table &amp; show table"></a>0x02 describe table &amp; show table</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">desc default.managed_user;</span><br><span class="line">desc formatted default.managed_user;</span><br><span class="line"></span><br><span class="line">show tables;</span><br><span class="line">show create table default.managed_user;</span><br><span class="line">show partitions default.partitioned_user;</span><br></pre></td></tr></table></figure><h2 id="0x03-truncate-table-amp-drop-table"><a href="#0x03-truncate-table-amp-drop-table" class="headerlink" title="0x03 truncate table &amp; drop table"></a>0x03 truncate table &amp; drop table</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">truncate table default.managed_user;</span><br><span class="line"></span><br><span class="line">drop table default.partitioned_user;</span><br><span class="line">alter table default.partitioned_user drop partition(dt = &apos;2019-09-22&apos;);</span><br></pre></td></tr></table></figure><h2 id="0x04-参考"><a href="#0x04-参考" class="headerlink" title="0x04 参考"></a>0x04 参考</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">LanguageManual DDL</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Hive数据仓库软件有助于读取，写入和管理驻留在分布式存储中并使用SQL语法查询的大型数据集。而Table是Hive组织数据存储的主要数据单元，是一种结构化存储，用二维表结构来表示。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hql" scheme="https://jordenbruce.com/tags/hql/"/>
    
  </entry>
  
  <entry>
    <title>yarn命令行的常用操作</title>
    <link href="https://jordenbruce.com/2019/09/22/yarn-cli/"/>
    <id>https://jordenbruce.com/2019/09/22/yarn-cli/</id>
    <published>2019-09-22T09:17:06.000Z</published>
    <updated>2019-09-22T10:39:56.718Z</updated>
    
    <content type="html"><![CDATA[<p>hadoop-0.23中引入的新架构将JobTracker的两个主要功能划分为：资源管理和作业生命周期管理。新的ResourceManager管理应用程序的全局计算资源分配，每个应用程序的ApplicationMaster管理应用程序的调度和协调。应用程序可以是传统yarnuce作业中的单个作业，也可以是此类作业的DAG。在该计算机上管理用户进程的ResourceManager和每台计算机的NodeManager守护程序构成了计算结构。实际上，每个应用程序的ApplicationMaster是特定于框架的库，其任务是与来自ResourceManager的资源进行协商，并与NodeManager一起执行和监视任务。<br><a id="more"></a></p><h2 id="0x00-yarn命令行的语法"><a href="#0x00-yarn命令行的语法" class="headerlink" title="0x00 yarn命令行的语法"></a>0x00 yarn命令行的语法</h2><p>YARN命令由bin/yarn脚本调用。在不带任何参数的情况下运行yarn脚本会打印所有命令的描述。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">Usage: yarn [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME                             run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  where COMMAND is one of:</span><br><span class="line">  resourcemanager -format-state-store   deletes the RMStateStore</span><br><span class="line">  resourcemanager                       run the ResourceManager</span><br><span class="line">  nodemanager                           run a nodemanager on each slave</span><br><span class="line">  timelineserver                        run the timeline server</span><br><span class="line">  rmadmin                               admin tools</span><br><span class="line">  sharedcachemanager                    run the SharedCacheManager daemon</span><br><span class="line">  scmadmin                              SharedCacheManager admin tools</span><br><span class="line">  version                               print the version</span><br><span class="line">  jar &lt;jar&gt;                             run a jar file</span><br><span class="line">  application                           prints application(s)</span><br><span class="line">                                        report/kill application</span><br><span class="line">  applicationattempt                    prints applicationattempt(s)</span><br><span class="line">                                        report</span><br><span class="line">  container                             prints container(s) report</span><br><span class="line">  node                                  prints node report(s)</span><br><span class="line">  queue                                 prints queue information</span><br><span class="line">  logs                                  dump container logs</span><br><span class="line">  classpath                             prints the class path needed to</span><br><span class="line">                                        get the Hadoop jar and the</span><br><span class="line">                                        required libraries</span><br><span class="line">  cluster                               prints cluster information</span><br><span class="line">  daemonlog                             get/set the log level for each</span><br><span class="line">                                        daemon</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br></pre></td></tr></table></figure><h2 id="0x01-yarn-queue"><a href="#0x01-yarn-queue" class="headerlink" title="0x01 yarn queue"></a>0x01 yarn queue</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn queue -status default</span><br></pre></td></tr></table></figure><h2 id="0x02-yarn-application"><a href="#0x02-yarn-application" class="headerlink" title="0x02 yarn application"></a>0x02 yarn application</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yarn application -list</span><br><span class="line">yarn application -status application_id</span><br><span class="line">yarn application -kill application_id</span><br></pre></td></tr></table></figure><h2 id="0x03-yarn-jar"><a href="#0x03-yarn-jar" class="headerlink" title="0x03 yarn jar"></a>0x03 yarn jar</h2><p>运行一个jar文件。用户可以将其YARN代码捆绑在jar文件中，并使用此命令执行它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar wordcount /input/ /output/</span><br></pre></td></tr></table></figure><h2 id="0x04-参考"><a href="#0x04-参考" class="headerlink" title="0x04 参考"></a>0x04 参考</h2><p><a href="https://hadoop.apache.org/docs/r2.7.6/hadoop-yarn/hadoop-yarn-site/YarnCommands.html" target="_blank" rel="noopener">YARN Commands Guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;hadoop-0.23中引入的新架构将JobTracker的两个主要功能划分为：资源管理和作业生命周期管理。新的ResourceManager管理应用程序的全局计算资源分配，每个应用程序的ApplicationMaster管理应用程序的调度和协调。应用程序可以是传统yarnuce作业中的单个作业，也可以是此类作业的DAG。在该计算机上管理用户进程的ResourceManager和每台计算机的NodeManager守护程序构成了计算结构。实际上，每个应用程序的ApplicationMaster是特定于框架的库，其任务是与来自ResourceManager的资源进行协商，并与NodeManager一起执行和监视任务。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="yarn" scheme="https://jordenbruce.com/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>hdfs命令行的常用操作</title>
    <link href="https://jordenbruce.com/2019/09/22/hdfs-cli/"/>
    <id>https://jordenbruce.com/2019/09/22/hdfs-cli/</id>
    <published>2019-09-22T07:26:53.000Z</published>
    <updated>2019-09-22T08:57:26.965Z</updated>
    
    <content type="html"><![CDATA[<p>HDFS是Hadoop应用程序使用的主要分布式存储。HDFS群集主要由管理文件系统元数据的NameNode和存储实际数据的DataNode组成。客户端与NameNode联系以获取文件元数据或文件修改，并直接与DataNode执行实际的文件I/O。<br><a id="more"></a></p><h2 id="0x00-hdfs命令行的语法"><a href="#0x00-hdfs命令行的语法" class="headerlink" title="0x00 hdfs命令行的语法"></a>0x00 hdfs命令行的语法</h2><p>所有HDFS命令均由bin/hdfs脚本调用。运行不带任何参数的hdfs脚本会打印所有命令的描述。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Usage: hdfs [--config confdir] [--loglevel loglevel] COMMAND</span><br><span class="line">       where COMMAND is one of:</span><br><span class="line">  dfs                  run a filesystem command on the file systems supported in Hadoop.</span><br><span class="line">  classpath            prints the classpath</span><br><span class="line">  namenode -format     format the DFS filesystem</span><br><span class="line">  secondarynamenode    run the DFS secondary namenode</span><br><span class="line">  namenode             run the DFS namenode</span><br><span class="line">  journalnode          run the DFS journalnode</span><br><span class="line">  zkfc                 run the ZK Failover Controller daemon</span><br><span class="line">  datanode             run a DFS datanode</span><br><span class="line">  dfsadmin             run a DFS admin client</span><br><span class="line">  haadmin              run a DFS HA admin client</span><br><span class="line">  fsck                 run a DFS filesystem checking utility</span><br><span class="line">  balancer             run a cluster balancing utility</span><br><span class="line">  jmxget               get JMX exported values from NameNode or DataNode.</span><br><span class="line">  mover                run a utility to move block replicas across</span><br><span class="line">                       storage types</span><br><span class="line">  oiv                  apply the offline fsimage viewer to an fsimage</span><br><span class="line">  oiv_legacy           apply the offline fsimage viewer to an legacy fsimage</span><br><span class="line">  oev                  apply the offline edits viewer to an edits file</span><br><span class="line">  fetchdt              fetch a delegation token from the NameNode</span><br><span class="line">  getconf              get config values from configuration</span><br><span class="line">  groups               get the groups which users belong to</span><br><span class="line">  snapshotDiff         diff two snapshots of a directory or diff the</span><br><span class="line">                       current directory contents with a snapshot</span><br><span class="line">  lsSnapshottableDir   list all snapshottable dirs owned by the current user</span><br><span class="line">                                                Use -help to see options</span><br><span class="line">  portmap              run a portmap service</span><br><span class="line">  nfs3                 run an NFS version 3 gateway</span><br><span class="line">  cacheadmin           configure the HDFS cache</span><br><span class="line">  crypto               configure HDFS encryption zones</span><br><span class="line">  storagepolicies      list/get/set block storage policies</span><br><span class="line">  version              print the version</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br></pre></td></tr></table></figure><h2 id="0x01-hdfs-dfs"><a href="#0x01-hdfs-dfs" class="headerlink" title="0x01 hdfs dfs"></a>0x01 hdfs dfs</h2><p>在Hadoop支持的文件系统上运行文件系统命令。目前Hadoop兼容文件系统有：Amazon S3，Azure Blob Storage，OpenStack Swift 。常用操作命令与 hadoop fs 类似，也建议使用 hadoop fs 命令。</p><p><a href="https://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-common/FileSystemShell.html" target="_blank" rel="noopener">File System Shell Guide</a></p><h2 id="0x02-hdfs-balancer"><a href="#0x02-hdfs-balancer" class="headerlink" title="0x02 hdfs balancer"></a>0x02 hdfs balancer</h2><p>HDFS数据不一定总是在整个DataNode上均匀地放置。一个常见的原因是向现有群集中添加了新的DataNode。HDFS为管理员提供了一个工具balancer，可以分析整个DataNode上的块放置和重新平衡数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs balancer -policy datanode -threshold 20 -include -f /tmp/hdfs-blancer.txt</span><br></pre></td></tr></table></figure><h2 id="0x03-hdfs-dfsadmin"><a href="#0x03-hdfs-dfsadmin" class="headerlink" title="0x03 hdfs dfsadmin"></a>0x03 hdfs dfsadmin</h2><p>dfsadmin 命令用于管理HDFS集群，这些命令常用于管理员。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hdfs dfsadmin -report -live</span><br><span class="line">hdfs dfsadmin -printTopology</span><br><span class="line">hdfs dfsadmin -refreshNodes</span><br><span class="line">hdfs dfsadmin -safemode get</span><br><span class="line">hdfs dfsadmin -setBalancerBandwidth 6250000</span><br></pre></td></tr></table></figure><h2 id="0x04-参考"><a href="#0x04-参考" class="headerlink" title="0x04 参考"></a>0x04 参考</h2><p><a href="https://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#dfsadmin" target="_blank" rel="noopener">HDFS Commands Guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;HDFS是Hadoop应用程序使用的主要分布式存储。HDFS群集主要由管理文件系统元数据的NameNode和存储实际数据的DataNode组成。客户端与NameNode联系以获取文件元数据或文件修改，并直接与DataNode执行实际的文件I/O。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hdfs" scheme="https://jordenbruce.com/tags/hdfs/"/>
    
  </entry>
  
  <entry>
    <title>hadoop命令行的常用操作</title>
    <link href="https://jordenbruce.com/2019/09/20/hadoop-cli/"/>
    <id>https://jordenbruce.com/2019/09/20/hadoop-cli/</id>
    <published>2019-09-20T14:49:53.000Z</published>
    <updated>2019-09-22T08:57:48.186Z</updated>
    
    <content type="html"><![CDATA[<p>编译并安装Hadoop分布式运行环境之后，第一个要用到的命令行就是hadoop。需要注意的是：每个发行版的命令行语法有些不一样，可以通过<code>hadoop -help</code>进行查看。<br><a id="more"></a></p><h2 id="0x00-hadoop命令行的语法"><a href="#0x00-hadoop命令行的语法" class="headerlink" title="0x00 hadoop命令行的语法"></a>0x00 hadoop命令行的语法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Usage: hadoop [--config confdir] [COMMAND | CLASSNAME]</span><br><span class="line">  CLASSNAME            run the class named CLASSNAME</span><br><span class="line"> or</span><br><span class="line">  where COMMAND is one of:</span><br><span class="line">  fs                   run a generic filesystem user client</span><br><span class="line">  version              print the version</span><br><span class="line">  jar &lt;jar&gt;            run a jar file</span><br><span class="line">                       note: please use &quot;yarn jar&quot; to launch</span><br><span class="line">                             YARN applications, not this command.</span><br><span class="line">  checknative [-a|-h]  check native hadoop and compression libraries availability</span><br><span class="line">  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively</span><br><span class="line">  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive</span><br><span class="line">  classpath            prints the class path needed to get the</span><br><span class="line">  credential           interact with credential providers</span><br><span class="line">                       Hadoop jar and the required libraries</span><br><span class="line">  daemonlog            get/set the log level for each daemon</span><br><span class="line">  trace                view and modify Hadoop tracing settings</span><br><span class="line"></span><br><span class="line">Most commands print help when invoked w/o parameters.</span><br></pre></td></tr></table></figure><p>每个命令的具体含义如下：</p><table><thead><tr><th>命令</th><th>说明</th></tr></thead><tbody><tr><td>version</td><td>打印hadoop版本</td></tr><tr><td>checknative</td><td>检测native库和压缩库的可用性</td></tr><tr><td>fs</td><td>hdfs命令行的客户端</td></tr><tr><td>jar</td><td>运行jar包里的mapreduce程序(推荐使用yarn jar)</td></tr><tr><td>distcp</td><td>用于大规模集群内部和集群之间拷贝的工具</td></tr><tr><td>archive</td><td>将小文件进行hadoop存档</td></tr><tr><td>classpath</td><td>打印类路径</td></tr><tr><td>credential</td><td>管理凭证供应商</td></tr><tr><td>daemonlog</td><td>获取/设置每个守护程序的日志级别</td></tr><tr><td>trace</td><td>查看和修改Hadoop跟踪设置</td></tr></tbody></table><p>其中，最常用的有 fs jar archive distcp 。</p><h2 id="0x01-hadoop-fs"><a href="#0x01-hadoop-fs" class="headerlink" title="0x01 hadoop fs"></a>0x01 hadoop fs</h2><p>调用文件系统(FS)Shell命令应使用 bin/hadoop fs <args>的形式。所有的的FS shell命令使用URI路径作为参数。URI格式是scheme://authority/path。对HDFS文件系统，scheme是hdfs，对本地文件系统，scheme是file。其中scheme和authority参数都是可选的，如果未加指定，就会使用配置中指定的默认scheme。一个HDFS文件或目录比如/parent/child可以表示成hdfs://namenode:namenodeport/parent/child，或者更简单的/parent/child（假设你配置文件中的默认值是namenode:namenodeport）。大多数FS Shell命令的行为和对应的Unix Shell命令类似。</args></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /</span><br><span class="line">hadoop fs -mkdir /external</span><br><span class="line">hadoop fs -touchz /external/readme</span><br><span class="line">hadoop fs -put $&#123;HADOOP_HOME&#125;README.txt /external</span><br><span class="line">hadoop fs -du -h /external</span><br><span class="line">hadoop fs -find /external readme</span><br><span class="line">hadoop fs -tail /external/README.txt</span><br><span class="line">hadoop fs -rm /external/readme</span><br></pre></td></tr></table></figure><p>还有很多命令，这里就不一一演示了。</p><h2 id="0x02-hadoop-archive"><a href="#0x02-hadoop-archive" class="headerlink" title="0x02 hadoop archive"></a>0x02 hadoop archive</h2><p>Hadoop archives是特殊的档案格式。一个Hadoop archive对应一个文件系统目录。Hadoop archive的扩展名是*.har。Hadoop archive包含元数据（形式是_index和_masterindx）和数据（part-*）文件。_index文件包含了档案中的文件的文件名和位置信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop archive -archiveName readme.har -p / external /archive</span><br><span class="line">hadoop fs -ls -R har:///archive/readme.har</span><br><span class="line">hadoop fs -cat har:///archive/readme.har/external/README.txt</span><br></pre></td></tr></table></figure><h2 id="0x03-hadoop-distcp"><a href="#0x03-hadoop-distcp" class="headerlink" title="0x03 hadoop distcp"></a>0x03 hadoop distcp</h2><p>DistCp（分布式拷贝）是用于大规模集群内部和集群之间拷贝的工具。它使用Map/Reduce实现文件分发，错误处理和恢复，以及报告生成。它把文件和目录的列表作为map任务的输入，每个任务会完成源列表中部分文件的拷贝。由于使用了Map/Reduce方法，这个工具在语义和执行上都会有特殊的地方。</p><p>DistCp最常用在集群之间的拷贝：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop distcp hdfs://nn1:8020/foo/bar hdfs://nn2:8020/bar/foo</span><br></pre></td></tr></table></figure><p>这条命令会把nn1集群的/foo/bar目录下的所有文件或目录名展开并存储到一个临时文件中，这些文件内容的拷贝工作被分配给多个map任务，然后每个TaskTracker分别执行从nn1到nn2的拷贝操作。注意DistCp使用绝对路径进行操作。</p><h2 id="0x04-参考"><a href="#0x04-参考" class="headerlink" title="0x04 参考"></a>0x04 参考</h2><p><a href="https://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-common/CommandsManual.html" target="_blank" rel="noopener">Hadoop Commands Guide</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;编译并安装Hadoop分布式运行环境之后，第一个要用到的命令行就是hadoop。需要注意的是：每个发行版的命令行语法有些不一样，可以通过&lt;code&gt;hadoop -help&lt;/code&gt;进行查看。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hadoop" scheme="https://jordenbruce.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>手动搭建Sqoop开发环境</title>
    <link href="https://jordenbruce.com/2019/09/15/sqoop-install/"/>
    <id>https://jordenbruce.com/2019/09/15/sqoop-install/</id>
    <published>2019-09-15T08:16:47.000Z</published>
    <updated>2019-09-17T14:16:05.939Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Sqoop 是一种工具，用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据。<br><a id="more"></a></p><h2 id="0x00-解压文件"><a href="#0x00-解压文件" class="headerlink" title="0x00 解压文件"></a>0x00 解压文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -xf sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz</span><br><span class="line">mv sqoop-1.4.7.bin__hadoop-2.6.0/ sqoop-1.4.7</span><br><span class="line">ln -s /data/sqoop-1.4.7/ /data/sqoop</span><br></pre></td></tr></table></figure><h2 id="0x01-添加环境变量"><a href="#0x01-添加环境变量" class="headerlink" title="0x01 添加环境变量"></a>0x01 添加环境变量</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">#export SQOOP_HOME=/data/sqoop/</span><br><span class="line">#export PATH=$&#123;SQOOP_HOME&#125;/bin:$PATH</span><br><span class="line">source ~/.bashrc</span><br><span class="line">sqoop version</span><br></pre></td></tr></table></figure><h2 id="0x02-修改sqoop-env-sh配置文件"><a href="#0x02-修改sqoop-env-sh配置文件" class="headerlink" title="0x02 修改sqoop-env.sh配置文件"></a>0x02 修改sqoop-env.sh配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cd conf/</span><br><span class="line">mv sqoop-env-template.sh sqoop-env.sh</span><br><span class="line">vim sqoop-env.sh</span><br><span class="line"></span><br><span class="line">#Set path to where bin/hadoop is available</span><br><span class="line">export HADOOP_COMMON_HOME=/data/hadoop/</span><br><span class="line"></span><br><span class="line">#Set path to where hadoop-*-core.jar is available</span><br><span class="line">export HADOOP_MAPRED_HOME=/data/hadoop/</span><br><span class="line"></span><br><span class="line">#set the path to where bin/hbase is available</span><br><span class="line">#export HBASE_HOME=</span><br><span class="line"></span><br><span class="line">#Set the path to where bin/hive is available</span><br><span class="line">export HIVE_HOME=/data/hive/</span><br><span class="line"></span><br><span class="line">#Set the path for where zookeper config dir is</span><br><span class="line">#export ZOOCFGDIR=</span><br></pre></td></tr></table></figure><h2 id="0x03-修改configure-sqoop文件"><a href="#0x03-修改configure-sqoop文件" class="headerlink" title="0x03 修改configure-sqoop文件"></a>0x03 修改configure-sqoop文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd bin/</span><br><span class="line">vim configure-sqoop</span><br></pre></td></tr></table></figure><p>注释掉以下代码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">#if [ -z &quot;$&#123;HBASE_HOME&#125;&quot; ]; then</span><br><span class="line">#  if [ -d &quot;/usr/lib/hbase&quot; ]; then</span><br><span class="line">#    HBASE_HOME=/usr/lib/hbase</span><br><span class="line">#  else</span><br><span class="line">#    HBASE_HOME=$&#123;SQOOP_HOME&#125;/../hbase</span><br><span class="line">#  fi</span><br><span class="line">#fi</span><br><span class="line">#if [ -z &quot;$&#123;HCAT_HOME&#125;&quot; ]; then</span><br><span class="line">#  if [ -d &quot;/usr/lib/hive-hcatalog&quot; ]; then</span><br><span class="line">#    HCAT_HOME=/usr/lib/hive-hcatalog</span><br><span class="line">#  elif [ -d &quot;/usr/lib/hcatalog&quot; ]; then</span><br><span class="line">#    HCAT_HOME=/usr/lib/hcatalog</span><br><span class="line">#  else</span><br><span class="line">#    HCAT_HOME=$&#123;SQOOP_HOME&#125;/../hive-hcatalog</span><br><span class="line">#    if [ ! -d $&#123;HCAT_HOME&#125; ]; then</span><br><span class="line">#       HCAT_HOME=$&#123;SQOOP_HOME&#125;/../hcatalog</span><br><span class="line">#    fi</span><br><span class="line">#  fi</span><br><span class="line">#fi</span><br><span class="line">#if [ -z &quot;$&#123;ACCUMULO_HOME&#125;&quot; ]; then</span><br><span class="line">#  if [ -d &quot;/usr/lib/accumulo&quot; ]; then</span><br><span class="line">#    ACCUMULO_HOME=/usr/lib/accumulo</span><br><span class="line">#  else</span><br><span class="line">#    ACCUMULO_HOME=$&#123;SQOOP_HOME&#125;/../accumulo</span><br><span class="line">#  fi</span><br><span class="line">#fi</span><br><span class="line">#if [ -z &quot;$&#123;ZOOKEEPER_HOME&#125;&quot; ]; then</span><br><span class="line">#  if [ -d &quot;/usr/lib/zookeeper&quot; ]; then</span><br><span class="line">#    ZOOKEEPER_HOME=/usr/lib/zookeeper</span><br><span class="line">#  else</span><br><span class="line">#    ZOOKEEPER_HOME=$&#123;SQOOP_HOME&#125;/../zookeeper</span><br><span class="line">#  fi</span><br><span class="line">#fi</span><br></pre></td></tr></table></figure><h2 id="0x04-拷贝数据库连接jar包"><a href="#0x04-拷贝数据库连接jar包" class="headerlink" title="0x04 拷贝数据库连接jar包"></a>0x04 拷贝数据库连接jar包</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp /data/hive/lib/mysql-connector-java-5.1.44-bin.jar ./lib/</span><br></pre></td></tr></table></figure><h2 id="0x05-启动测试"><a href="#0x05-启动测试" class="headerlink" title="0x05 启动测试"></a>0x05 启动测试</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">sqoop list-databases --connect jdbc:mysql://localhost:3306/ --username root --password</span><br><span class="line">sqoop list-tables --connect jdbc:mysql://localhost:3306/hive --username root --password</span><br><span class="line"></span><br><span class="line">sqoop import \</span><br><span class="line">--connect jdbc:mysql://mdw01:3306/hive \</span><br><span class="line">--username hive --password mysql \</span><br><span class="line">--table TBLS \</span><br><span class="line">-m 1 \</span><br><span class="line">--hive-import \</span><br><span class="line">--create-hive-table \</span><br><span class="line">--hive-table hive_tables</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Sqoop 是一种工具，用于在Apache Hadoop和结构化数据存储（如关系数据库）之间高效传输批量数据。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="sqoop" scheme="https://jordenbruce.com/tags/sqoop/"/>
    
  </entry>
  
  <entry>
    <title>手动搭建Hive开发环境</title>
    <link href="https://jordenbruce.com/2019/09/15/hive-install/"/>
    <id>https://jordenbruce.com/2019/09/15/hive-install/</id>
    <published>2019-09-15T07:36:31.000Z</published>
    <updated>2019-09-17T14:16:28.583Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Hive 数据仓库软件有助于使用 SQL 读取，编写和管理驻留在分布式存储中的大型数据集。可以将结构投影到已存储的数据中。提供了命令行工具和 JDBC 驱动程序以将用户连接到 Hive<br><a id="more"></a></p><h2 id="0x00-安装-MySQL-5-6"><a href="#0x00-安装-MySQL-5-6" class="headerlink" title="0x00 安装 MySQL 5.6"></a>0x00 安装 MySQL 5.6</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">yum update gcc gcc-c++ make cmake openssl openssl-devel -y</span><br><span class="line">yum update bison bison-devel ncurses ncurses-devel zlib zlib-devel libaio libaio-devel -y</span><br><span class="line"></span><br><span class="line">yum install gcc gcc-c++ make cmake openssl openssl-devel -y</span><br><span class="line">yum install bison bison-devel ncurses ncurses-devel zlib zlib-devel libaio libaio-devel -y</span><br><span class="line"></span><br><span class="line">tar -xf MySQL-5.6.24-1.el6.x86_64.rpm-bundle.tar</span><br><span class="line">rpm -ihv MySQL-shared-compat-5.6.24-1.el6.x86_64.rpm</span><br><span class="line">rpm -e mysql-libs-5.1.71-1.el6.x86_64</span><br><span class="line"></span><br><span class="line">groupadd mysql</span><br><span class="line">useradd mysql -s /sbin/nologin -M -g mysql</span><br><span class="line"></span><br><span class="line">rpm -ivh MySQL-server-5.6.24-1.el6.x86_64.rpm</span><br><span class="line">rpm -ivh MySQL-client-5.6.24-1.el6.x86_64.rpm</span><br><span class="line">rpm -ihv MySQL-devel-5.6.24-1.el6.x86_64.rpm</span><br><span class="line">rpm -ihv MySQL-shared-5.6.24-1.el6.x86_64.rpm</span><br><span class="line"></span><br><span class="line">cat /root/.mysql_secret</span><br><span class="line">service mysql start</span><br><span class="line">/usr/bin/mysql_secure_installation --user=mysql</span><br></pre></td></tr></table></figure><p><em>注意：mysql默认字符集必须设置为 latin1</em></p><h2 id="0x01-配置Hive元数据库"><a href="#0x01-配置Hive元数据库" class="headerlink" title="0x01 配置Hive元数据库"></a>0x01 配置Hive元数据库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; mysql -uroot -p --default-character-set=latin1</span><br><span class="line">mysql&gt; CREATE USER &apos;hive&apos; IDENTIFIED BY &apos;mysql&apos;;</span><br><span class="line">mysql&gt; GRANT ALL PRIVILEGES ON hive.* TO &apos;hive&apos;@&apos;%&apos; WITH GRANT OPTION;</span><br><span class="line">mysql&gt; FLUSH PRIVILEGES;</span><br><span class="line">mysql&gt; EXIT;</span><br></pre></td></tr></table></figure><h2 id="0x02-配置Hive"><a href="#0x02-配置Hive" class="headerlink" title="0x02 配置Hive"></a>0x02 配置Hive</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tar -zxf apache-hive-1.2.2-bin.tar.gz -C /data/</span><br><span class="line">ln -s /data/apache-hive-1.2.2-bin/ /data/hive</span><br><span class="line">cd /data/hive/conf/</span><br><span class="line">cp hive-default.xml.template hive-site.xml</span><br><span class="line">vim hive-site.xml</span><br><span class="line"></span><br><span class="line">mv mysql-connector-java-5.1.44-bin.jar /data/hive/lib/</span><br><span class="line">cp lib/jline-2.12.jar /data/hadoop/share/hadoop/yarn/lib/</span><br><span class="line">vim ./bin/hive</span><br></pre></td></tr></table></figure><h2 id="0x03-启动Hive"><a href="#0x03-启动Hive" class="headerlink" title="0x03 启动Hive"></a>0x03 启动Hive</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br><span class="line"></span><br><span class="line">hadoop fs -mkdir       /tmp</span><br><span class="line">hadoop fs -mkdir -p    /user/hive/warehouse</span><br><span class="line">hadoop fs -chmod g+w   /tmp</span><br><span class="line">hadoop fs -chmod g+w   /user/hive/warehouse</span><br><span class="line"></span><br><span class="line">hive</span><br><span class="line">$HIVE_HOME/bin/beeline -u jdbc:hive2://</span><br></pre></td></tr></table></figure><h2 id="0x04-hive-site-xml"><a href="#0x04-hive-site-xml" class="headerlink" title="0x04 hive-site.xml"></a>0x04 hive-site.xml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line"></span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;jdbc:mysql://mdw01:3306/hive?characterEncoding=UTF-8&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hive&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mysql&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt; </span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><h2 id="0x05-参考"><a href="#0x05-参考" class="headerlink" title="0x05 参考"></a>0x05 参考</h2><p><a href="https://blog.csdn.net/wjqwinn/article/details/52692308" target="_blank" rel="noopener">Hive在spark2.0.0启动时无法访问spark-assembly-*.jar的解决办法</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Hive 数据仓库软件有助于使用 SQL 读取，编写和管理驻留在分布式存储中的大型数据集。可以将结构投影到已存储的数据中。提供了命令行工具和 JDBC 驱动程序以将用户连接到 Hive&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hive" scheme="https://jordenbruce.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>手动搭建Hadoop分布式运行环境</title>
    <link href="https://jordenbruce.com/2019/09/15/hadoop-install/"/>
    <id>https://jordenbruce.com/2019/09/15/hadoop-install/</id>
    <published>2019-09-15T04:56:42.000Z</published>
    <updated>2019-09-22T09:02:38.409Z</updated>
    
    <content type="html"><![CDATA[<p>当开始着手实践 Hadoop 时，安装 Hadoop 往往会成为新手的一道门槛。尽管安装其实很简单，书上有写到，官方网站也有 Hadoop 安装配置教程，但由于对 Linux 环境不熟悉，书上跟官网上简略的安装步骤新手往往 Hold 不住。加之网上不少教程也甚是坑，导致新手折腾老几天愣是没装好，很是打击学习热情。<br><a id="more"></a></p><h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>本教程详细记录了 hadoop 安装的全过程，还有配置文件的参数设置，一次性解决安装过程的所有问题。</p><h2 id="0x01-虚拟服务器"><a href="#0x01-虚拟服务器" class="headerlink" title="0x01 虚拟服务器"></a>0x01 虚拟服务器</h2><p>VMware Workstation 11.0</p><table><thead><tr><th>host</th><th>ip</th><th>os</th><th>role</th><th>cpu</th><th>memory</th><th>disk</th></tr></thead><tbody><tr><td>mdw01</td><td>192.168.100.186</td><td>CentOS 6.8 x64</td><td>master</td><td>1*2</td><td>8GB</td><td>30GB</td></tr><tr><td>sdw02</td><td>192.168.100.187</td><td>CentOS 6.8 x64</td><td>slave</td><td>1*2</td><td>4GB</td><td>30GB</td></tr><tr><td>sdw03</td><td>192.168.100.188</td><td>CentOS 6.8 x64</td><td>slave</td><td>1*2</td><td>4GB</td><td>30GB</td></tr></tbody></table><h2 id="0x02-系统配置"><a href="#0x02-系统配置" class="headerlink" title="0x02 系统配置"></a>0x02 系统配置</h2><p>(1) 修改主机名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostname</span><br><span class="line">cat /etc/sysconfig/network</span><br><span class="line">vim /etc/hosts</span><br></pre></td></tr></table></figure><p>(2) 关闭SELinux</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">vim /etc/selinux/config</span><br><span class="line">sestatus</span><br></pre></td></tr></table></figure><p>(3) 关闭iptables</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">chkconfig iptables off</span><br></pre></td></tr></table></figure><p>(4) 安装JDK</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/</span><br><span class="line">tar -xf jdk-8u112-linux-x64.tar.gz</span><br><span class="line">chown -R root:root jdk1.8.0_112/</span><br><span class="line">ln -s /opt/jdk1.8.0_112/ /opt/java</span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line">java -version</span><br><span class="line">rm -f jdk-8u112-linux-x64.tar.gz</span><br></pre></td></tr></table></figure><p>(5) 免密登陆ssh</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br><span class="line">/etc/init.d/sshd restart</span><br><span class="line"></span><br><span class="line">useradd hadoop</span><br><span class="line">passwd hadoop</span><br><span class="line"></span><br><span class="line">ls -l /etc/sudoers</span><br><span class="line">chmod 640 /etc/sudoers</span><br><span class="line">vim /etc/sudoers</span><br><span class="line">chmod 0440 /etc/sudoers</span><br><span class="line"></span><br><span class="line">su hadoop</span><br><span class="line">ssh-keygen</span><br><span class="line">cd ~/.ssh/</span><br><span class="line">cat id_rsa.pub &gt;&gt; authorized_keys</span><br><span class="line">chmod 700 ~/.ssh</span><br><span class="line">chmod 600 ~/.ssh/authorized_keys</span><br><span class="line">scp authorized_keys hadoop@sdw02:~/.ssh/</span><br><span class="line">ssh hadoop@sdw03</span><br></pre></td></tr></table></figure><p>(6) 时间同步NTP服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">rpm -q ntp</span><br><span class="line">chkconfig ntpd on</span><br><span class="line">ntpdate -u 202.112.10.36</span><br><span class="line">hwclock -w</span><br><span class="line">vim /etc/ntp.conf</span><br><span class="line">vim /etc/sysconfig/ntpd</span><br><span class="line">service ntpd start</span><br><span class="line">netstat -tlunp | grep ntp</span><br><span class="line">ntpq -p</span><br></pre></td></tr></table></figure><h2 id="0x03-安装Hadoop"><a href="#0x03-安装Hadoop" class="headerlink" title="0x03 安装Hadoop"></a>0x03 安装Hadoop</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">chown -R hadoop:hadoop /data/</span><br><span class="line">cd /data/</span><br><span class="line">tar -xf hadoop-2.6.4.tar.gz</span><br><span class="line">ln -s /data/hadoop-2.6.4/ /data/hadoop</span><br><span class="line">vim ~/.bashrc</span><br><span class="line"></span><br><span class="line">cd /data/hadoop/etc/hadoop</span><br><span class="line">vim hadoop-env.sh</span><br><span class="line">#vim yarn-env.sh</span><br><span class="line">vim core-site.xml</span><br><span class="line">vim hdfs-site.xml</span><br><span class="line">vim mapred-site.xml</span><br><span class="line">vim yarn-site.xml</span><br><span class="line">vim slaves</span><br><span class="line"></span><br><span class="line">cd /data/hadoop/bin/</span><br><span class="line">./hdfs namenode -format</span><br><span class="line">cd /data/hadoop/sbin/</span><br><span class="line">./start-dfs.sh</span><br><span class="line">./start-yarn.sh</span><br><span class="line">./mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">./yarn-daemon.sh start proxyserver</span><br><span class="line"></span><br><span class="line">./stop-all.sh</span><br></pre></td></tr></table></figure><p>配置文件的详细参数设置，请参考 <a href="https://github.com/jordenbruce/archive/blob/master/hadoop_conf_file.zip" target="_blank" rel="noopener">hadoop_conf_files</a></p><p>安装完成后，访问下HDFS和Yarn地址：<br>HDFS：<a href="http://mdw01:50070/dfshealth.html#tab-overview" target="_blank" rel="noopener">http://mdw01:50070/dfshealth.html#tab-overview</a><br>Yarn：<a href="http://mdw01:8088/cluster" target="_blank" rel="noopener">http://mdw01:8088/cluster</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当开始着手实践 Hadoop 时，安装 Hadoop 往往会成为新手的一道门槛。尽管安装其实很简单，书上有写到，官方网站也有 Hadoop 安装配置教程，但由于对 Linux 环境不熟悉，书上跟官网上简略的安装步骤新手往往 Hold 不住。加之网上不少教程也甚是坑，导致新手折腾老几天愣是没装好，很是打击学习热情。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hadoop" scheme="https://jordenbruce.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>编译Hadoop源码包</title>
    <link href="https://jordenbruce.com/2019/09/15/hadoop-build/"/>
    <id>https://jordenbruce.com/2019/09/15/hadoop-build/</id>
    <published>2019-09-15T04:02:01.000Z</published>
    <updated>2019-09-15T08:31:16.981Z</updated>
    
    <content type="html"><![CDATA[<p>Hadoop社区不提供64位编译好的版本，只能用源码自行编译64位版本。学习一项技术从安装开始，学习Hadoop要从编译开始。<br><a id="more"></a></p><h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>本文档编译的hadoop版本是hadoop-2.6.4-src.tar.gz</p><p><strong>重要提示</strong>：源码包编译的官方文档是压缩包的根目录下BUILDING.txt说明书。</p><p><img src="https://i.loli.net/2019/09/15/V4LJv1n2lOpqiyg.png" alt="Build instructions for Hadoop"></p><p><strong>安装问题的引入</strong>：Hadoop社区不提供64位编译好的版本，只能用源码自行编译64位版本。学习一项技术从安装开始，学习Hadoop要从编译开始。</p><h2 id="0x01-编译环境说明"><a href="#0x01-编译环境说明" class="headerlink" title="0x01 编译环境说明"></a>0x01 编译环境说明</h2><p>操作系统：Red Hat Enterprise Linux Server release 6.5 (Santiago)<br>核心信息：Kernel 2.6.32-431.el6.x86_64 on an x86_64</p><h2 id="0x02-安装系统支持包"><a href="#0x02-安装系统支持包" class="headerlink" title="0x02 安装系统支持包"></a>0x02 安装系统支持包</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum -y install autoconf automake libtool cmake</span><br><span class="line">yum -y install ncurses-devel</span><br><span class="line">yum -y install openssl-devel</span><br><span class="line">yum -y install lzo-devel zlib-devel gcc gcc-c++</span><br><span class="line">yum -y install gcc gcc-c++ make</span><br></pre></td></tr></table></figure><h2 id="0x03-组件安装"><a href="#0x03-组件安装" class="headerlink" title="0x03 组件安装"></a>0x03 组件安装</h2><p>将所有组件包上传到主机/usr/local/src/目录下。</p><p>（1）安装JDK</p><p><em>注意：只能用1.7，否则编译会出错。</em> </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf jdk-7u80-linux-x64.tar.gz -C /opt/modules/</span><br><span class="line">vi /etc/profile</span><br><span class="line">export JAVA_HOME=/opt/modules/jdk1.7.0_80</span><br><span class="line">export JRE_HOME=$JAVA_HOME/jre</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin</span><br></pre></td></tr></table></figure><p>（2）安装Maven</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf apache-maven-3.3.1-bin.tar.gz -C /opt/modules/</span><br><span class="line">vi /etc/profile</span><br><span class="line">export MAVEN_HOME=/opt/modules/apache-maven-3.3.1</span><br><span class="line">export PATH=$PATH:$MAVEN_HOME/bin</span><br><span class="line">vi /opt/modules/apache-maven-3.3.1/conf/settings.xml</span><br></pre></td></tr></table></figure><p>更改maven资料库，在<mirrors>里添加如下内容：</mirrors></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;mirror&gt;</span><br><span class="line">&lt;id&gt;nexus-osc&lt;/id&gt;</span><br><span class="line">&lt;mirrorOf&gt;*&lt;/mirrorOf&gt;</span><br><span class="line">&lt;name&gt;Nexus osc&lt;/name&gt;</span><br><span class="line">&lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;</span><br><span class="line">&lt;/mirror&gt;</span><br></pre></td></tr></table></figure><p>在<code>&lt;profiles&gt;&lt;/profiles&gt;</code>内新添加：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">&lt;profile&gt;</span><br><span class="line">&lt;id&gt;jdk-1.7&lt;/id&gt;</span><br><span class="line">&lt;activation&gt;</span><br><span class="line">&lt;jdk&gt;1.7&lt;/jdk&gt;</span><br><span class="line">&lt;/activation&gt;</span><br><span class="line">&lt;repositories&gt;</span><br><span class="line">&lt;repository&gt;</span><br><span class="line">&lt;id&gt;nexus&lt;/id&gt;</span><br><span class="line">&lt;name&gt;local private nexus&lt;/name&gt;</span><br><span class="line">&lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;</span><br><span class="line">&lt;releases&gt;</span><br><span class="line">&lt;enabled&gt;true&lt;/enabled&gt;</span><br><span class="line">&lt;/releases&gt;</span><br><span class="line">&lt;snapshots&gt;</span><br><span class="line">&lt;enabled&gt;false&lt;/enabled&gt;</span><br><span class="line">&lt;/snapshots&gt;</span><br><span class="line">&lt;/repository&gt;</span><br><span class="line">&lt;/repositories&gt;</span><br><span class="line">&lt;pluginRepositories&gt;</span><br><span class="line">&lt;pluginRepository&gt;</span><br><span class="line">&lt;id&gt;nexus&lt;/id&gt;</span><br><span class="line">&lt;name&gt;local private nexus&lt;/name&gt;</span><br><span class="line">&lt;url&gt;http://maven.oschina.net/content/groups/public/&lt;/url&gt;</span><br><span class="line">&lt;releases&gt;</span><br><span class="line">&lt;enabled&gt;true&lt;/enabled&gt;</span><br><span class="line">&lt;/releases&gt;</span><br><span class="line">&lt;snapshots&gt;</span><br><span class="line">&lt;enabled&gt;false&lt;/enabled&gt;</span><br><span class="line">&lt;/snapshots&gt;</span><br><span class="line">&lt;/pluginRepository&gt;</span><br><span class="line">&lt;/pluginRepositories&gt;</span><br><span class="line">&lt;/profile&gt;</span><br></pre></td></tr></table></figure><p>如果不是第一次编译，可以配置本地仓库：<br><code>&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt;</code></p><p>（3）安装Findbugs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf findbugs-3.0.1.tar.gz -C /opt/modules/</span><br><span class="line">vi /etc/profile</span><br><span class="line">export FINDBUGS_HOME=/opt/modules/findbugs-3.0.1</span><br><span class="line">export PATH=$PATH:$FINDBUGS_HOME/bin</span><br></pre></td></tr></table></figure><p>（4）安装ProtocolBuffer</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tar xvf protobuf-2.5.0.tar.gz</span><br><span class="line">cd protobuf-2.5.0</span><br><span class="line">./configure --prefix=/opt/modules/protobuf</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">ldconfig</span><br><span class="line">protoc --version</span><br></pre></td></tr></table></figure><p>（5）<font color="red">上网</font>  </p><p>由于编译Hadoop过程中，Maven需要下载依赖库，所以必须保证主机能上网。</p><p>（6）安装Snappy（可选）</p><h2 id="0x04-源码编译"><a href="#0x04-源码编译" class="headerlink" title="0x04 源码编译"></a>0x04 源码编译</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">java -version</span><br><span class="line">mvn -version</span><br><span class="line">findbugs -version</span><br><span class="line">protoc --version</span><br><span class="line">ping www.baidu.com</span><br><span class="line"></span><br><span class="line">tar zxvf hadoop-2.6.4-src.tar.gz -C /opt/</span><br><span class="line">cd hadoop-2.6.4-src/</span><br><span class="line">export MAVEN_OPTS=&quot;-Xms256m -Xmx512m&quot;</span><br><span class="line">mvn clean package -Pdist,native,docs -DskipTests -Dtar</span><br></pre></td></tr></table></figure><p>剩下的就交给电脑，人可以出去锻炼身体了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] Apache Hadoop Main ................................. SUCCESS [06:32 min]</span><br><span class="line">[INFO] Apache Hadoop Project POM .......................... SUCCESS [03:46 min]</span><br><span class="line">[INFO] Apache Hadoop Annotations .......................... SUCCESS [01:29 min]</span><br><span class="line">[INFO] Apache Hadoop Assemblies ........................... SUCCESS [  0.329 s]</span><br><span class="line">[INFO] Apache Hadoop Project Dist POM ..................... SUCCESS [07:17 min]</span><br><span class="line">[INFO] Apache Hadoop Maven Plugins ........................ SUCCESS [ 57.156 s]</span><br><span class="line">[INFO] Apache Hadoop MiniKDC .............................. SUCCESS [06:10 min]</span><br><span class="line">[INFO] Apache Hadoop Auth ................................. SUCCESS [05:18 min]</span><br><span class="line">[INFO] Apache Hadoop Auth Examples ........................ SUCCESS [ 27.119 s]</span><br><span class="line">[INFO] Apache Hadoop Common ............................... SUCCESS [09:30 min]</span><br><span class="line">[INFO] Apache Hadoop NFS .................................. SUCCESS [  6.677 s]</span><br><span class="line">[INFO] Apache Hadoop KMS .................................. SUCCESS [04:45 min]</span><br><span class="line">[INFO] Apache Hadoop Common Project ....................... SUCCESS [  0.040 s]</span><br><span class="line">[INFO] Apache Hadoop HDFS ................................. SUCCESS [13:03 min]</span><br><span class="line">[INFO] Apache Hadoop HttpFS ............................... SUCCESS [04:10 min]</span><br><span class="line">[INFO] Apache Hadoop HDFS BookKeeper Journal .............. SUCCESS [01:44 min]</span><br><span class="line">[INFO] Apache Hadoop HDFS-NFS ............................. SUCCESS [  5.085 s]</span><br><span class="line">[INFO] Apache Hadoop HDFS Project ......................... SUCCESS [  0.033 s]</span><br><span class="line">[INFO] hadoop-yarn ........................................ SUCCESS [  0.059 s]</span><br><span class="line">[INFO] hadoop-yarn-api .................................... SUCCESS [01:25 min]</span><br><span class="line">[INFO] hadoop-yarn-common ................................. SUCCESS [01:29 min]</span><br><span class="line">[INFO] hadoop-yarn-server ................................. SUCCESS [  0.095 s]</span><br><span class="line">[INFO] hadoop-yarn-server-common .......................... SUCCESS [ 42.211 s]</span><br><span class="line">[INFO] hadoop-yarn-server-nodemanager ..................... SUCCESS [01:51 min]</span><br><span class="line">[INFO] hadoop-yarn-server-web-proxy ....................... SUCCESS [  2.956 s]</span><br><span class="line">[INFO] hadoop-yarn-server-applicationhistoryservice ....... SUCCESS [  7.023 s]</span><br><span class="line">[INFO] hadoop-yarn-server-resourcemanager ................. SUCCESS [ 23.905 s]</span><br><span class="line">[INFO] hadoop-yarn-server-tests ........................... SUCCESS [ 45.162 s]</span><br><span class="line">[INFO] hadoop-yarn-client ................................. SUCCESS [  8.784 s]</span><br><span class="line">[INFO] hadoop-yarn-applications ........................... SUCCESS [  0.047 s]</span><br><span class="line">[INFO] hadoop-yarn-applications-distributedshell .......... SUCCESS [  2.790 s]</span><br><span class="line">[INFO] hadoop-yarn-applications-unmanaged-am-launcher ..... SUCCESS [  2.169 s]</span><br><span class="line">[INFO] hadoop-yarn-site ................................... SUCCESS [  0.052 s]</span><br><span class="line">[INFO] hadoop-yarn-registry ............................... SUCCESS [  5.526 s]</span><br><span class="line">[INFO] hadoop-yarn-project ................................ SUCCESS [  5.919 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client ............................ SUCCESS [  0.083 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-core ....................... SUCCESS [ 25.201 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-common ..................... SUCCESS [ 19.914 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-shuffle .................... SUCCESS [  3.998 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-app ........................ SUCCESS [ 11.686 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-hs ......................... SUCCESS [  8.481 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-jobclient .................. SUCCESS [ 28.587 s]</span><br><span class="line">[INFO] hadoop-mapreduce-client-hs-plugins ................. SUCCESS [  1.978 s]</span><br><span class="line">[INFO] Apache Hadoop MapReduce Examples ................... SUCCESS [  6.412 s]</span><br><span class="line">[INFO] hadoop-mapreduce ................................... SUCCESS [  4.931 s]</span><br><span class="line">[INFO] Apache Hadoop MapReduce Streaming .................. SUCCESS [ 44.811 s]</span><br><span class="line">[INFO] Apache Hadoop Distributed Copy ..................... SUCCESS [  8.613 s]</span><br><span class="line">[INFO] Apache Hadoop Archives ............................. SUCCESS [  2.769 s]</span><br><span class="line">[INFO] Apache Hadoop Rumen ................................ SUCCESS [  6.654 s]</span><br><span class="line">[INFO] Apache Hadoop Gridmix .............................. SUCCESS [  5.080 s]</span><br><span class="line">[INFO] Apache Hadoop Data Join ............................ SUCCESS [  3.253 s]</span><br><span class="line">[INFO] Apache Hadoop Ant Tasks ............................ SUCCESS [  2.646 s]</span><br><span class="line">[INFO] Apache Hadoop Extras ............................... SUCCESS [  4.990 s]</span><br><span class="line">[INFO] Apache Hadoop Pipes ................................ SUCCESS [  8.460 s]</span><br><span class="line">[INFO] Apache Hadoop OpenStack support .................... SUCCESS [  5.232 s]</span><br><span class="line">[INFO] Apache Hadoop Amazon Web Services support .......... SUCCESS [06:09 min]</span><br><span class="line">[INFO] Apache Hadoop Client ............................... SUCCESS [  8.045 s]</span><br><span class="line">[INFO] Apache Hadoop Mini-Cluster ......................... SUCCESS [  0.145 s]</span><br><span class="line">[INFO] Apache Hadoop Scheduler Load Simulator ............. SUCCESS [  7.135 s]</span><br><span class="line">[INFO] Apache Hadoop Tools Dist ........................... SUCCESS [ 12.856 s]</span><br><span class="line">[INFO] Apache Hadoop Tools ................................ SUCCESS [  0.027 s]</span><br><span class="line">[INFO] Apache Hadoop Distribution ......................... SUCCESS [02:45 min]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 01:27 h</span><br><span class="line">[INFO] Finished at: 2016-11-05T15:02:45+08:00</span><br><span class="line">[INFO] Final Memory: 112M/369M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>编译成功后会打包，放在hadoop-dist/target目录下。</p><p><img src="https://i.loli.net/2019/09/15/lus6tF8BawgU7YK.png" alt="dist_target_dir"></p><p>hadoop-2.6.4.tar.gz 就是编译成功的二进制安装包，大功告成！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hadoop社区不提供64位编译好的版本，只能用源码自行编译64位版本。学习一项技术从安装开始，学习Hadoop要从编译开始。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hadoop" scheme="https://jordenbruce.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop发行版的选取</title>
    <link href="https://jordenbruce.com/2019/09/15/hadoop-release/"/>
    <id>https://jordenbruce.com/2019/09/15/hadoop-release/</id>
    <published>2019-09-15T01:19:22.000Z</published>
    <updated>2019-09-17T14:21:44.756Z</updated>
    
    <content type="html"><![CDATA[<p>Apache Hadoop的开源协议决定了任何人可以对其进行修改，并作为开源或者商业版发布/销售。故而，目前Hadoop的发行版非常多，除了Apache的开源版本之外，还有Cloudera发行版(CDH)、Hortonworks发行版（HDP）、MapR等，这些发行版都是基于Apache Hadoop衍生出来的。<br><a id="more"></a></p><h2 id="0x00-综述"><a href="#0x00-综述" class="headerlink" title="0x00 综述"></a>0x00 综述</h2><p>其中，不收费的Hadoop发行版主要有三个，分别是：</p><ul><li>Apache基金会hadoop</li><li>Cloudera版本（Cloudera’s Distribution Including Apache Hadoop，简称“CDH”）</li><li>Hortonworks版本（Hortonworks Data Platform，简称“HDP”）</li></ul><p>在我任职过的公司当中，telecom使用了CDH，analysys使用了HDP，qtt使用了Apache Hadoop</p><h2 id="0x01-发行版的比较"><a href="#0x01-发行版的比较" class="headerlink" title="0x01 发行版的比较"></a>0x01 发行版的比较</h2><table><thead><tr><th>\</th><th>Apache Hadoop</th><th>CDH</th><th>HDP</th></tr></thead><tbody><tr><td>开源情况</td><td>100%开源</td><td>100%开源</td><td>100%开源</td></tr><tr><td>收费情况</td><td>完全免费</td><td>免费版和企业版</td><td>完全免费</td></tr><tr><td>管理工具</td><td>Apache Ambari</td><td>Cloudera Manager</td><td>Ambari</td></tr><tr><td>稳定性</td><td>中</td><td>高</td><td>高</td></tr><tr><td>运维成本</td><td>高</td><td>中</td><td>中</td></tr><tr><td>生态支持</td><td>兼容性差</td><td>完善</td><td>完善</td></tr></tbody></table><h2 id="0x02-选择决定"><a href="#0x02-选择决定" class="headerlink" title="0x02 选择决定"></a>0x02 选择决定</h2><p>考虑到大数据平台高效的部署和安装，中心化的配置管理，使用过程中的稳定性、兼容性、扩展性，<br>以及未来较为简单、高效的运维，遇到问题低廉的解决成本；建议使用第三方发行版本。</p><p>然而，本系列教程选取了Apache Hadoop社区版，考虑的是完全开源免费、社区活跃、文档与资料详实，便于深入学习。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Apache Hadoop的开源协议决定了任何人可以对其进行修改，并作为开源或者商业版发布/销售。故而，目前Hadoop的发行版非常多，除了Apache的开源版本之外，还有Cloudera发行版(CDH)、Hortonworks发行版（HDP）、MapR等，这些发行版都是基于Apache Hadoop衍生出来的。&lt;br&gt;
    
    </summary>
    
      <category term="Data Warehouse" scheme="https://jordenbruce.com/categories/Data-Warehouse/"/>
    
    
      <category term="hadoop" scheme="https://jordenbruce.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hive自定义函数</title>
    <link href="https://jordenbruce.com/2019/03/14/hive-udf/"/>
    <id>https://jordenbruce.com/2019/03/14/hive-udf/</id>
    <published>2019-03-14T11:11:30.000Z</published>
    <updated>2019-09-22T09:10:33.216Z</updated>
    
    <content type="html"><![CDATA[<p>Hive自带了许多内置函数（Built-in Functions），方便数据的处理分析。可是，有时候内置函数无法满足需求，这就需要自定义函数（User-Defined Functions , UDF）来实现想要的功能。<br><a id="more"></a></p><h2 id="1-创建自定义UDF"><a href="#1-创建自定义UDF" class="headerlink" title="1. 创建自定义UDF"></a>1. 创建自定义UDF</h2><p>编写UDF需要下面两个步骤：</p><ul><li>继承 <code>org.apache.hadoop.hive.ql.exec.UDF</code> </li><li>实现 <code>evaluate</code> 函数，这个函数必须要有返回值，不能设置为void。同时建议使用mapreduce编程模型中的数据类型(Text,IntWritable等)，因为hive语句会被转换为mapreduce任务。</li></ul><p>完整的开发过程 请参考 <a href="https://blog.csdn.net/qq_32653877/article/details/87182898" target="_blank" rel="noopener">Java编写Hive的UDF</a></p><h2 id="2-自定义UDF的部署方式"><a href="#2-自定义UDF的部署方式" class="headerlink" title="2. 自定义UDF的部署方式"></a>2. 自定义UDF的部署方式</h2><p>官方提供了两种部署UDF的方式：</p><ul><li>临时部署（Temporary Functions）</li><li>永久部署（Permanent Functions）</li></ul><p>两者的区别在于：临时部署的方式，只会在当前Session下有效并可用；永久部署的方式，在部署成功后任何一个Hive客户端（重新启动的Hive客户端，已经启动的客户端需要重新加载）都可以使用。</p><h3 id="2-1-临时部署"><a href="#2-1-临时部署" class="headerlink" title="2.1 临时部署"></a>2.1 临时部署</h3><p>这个是最常见的Hive使用方式，通过hive命令来完成UDF的部署；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; add jar /path/to/local.jar; </span><br><span class="line">hive&gt; create temporary function ua_parser as &apos;net.qutoutiao.data.hive.ParseUserAgent&apos;;</span><br></pre></td></tr></table></figure></p><p>建议函数名使用 <strong>下划线命名法</strong>（全部小写字母）。</p><h3 id="2-2-永久部署"><a href="#2-2-永久部署" class="headerlink" title="2.2 永久部署"></a>2.2 永久部署</h3><p>这种方式是 hive 0.13版本以后开始支持的注册方法；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hive&gt; create function udf.ua_parser </span><br><span class="line">hive&gt; as &apos;net.qutoutiao.data.hive.ParseUserAgent&apos; </span><br><span class="line">hive&gt; using jar &apos;hdfs:///path/to/hive-udf-1.0.jar&apos;;</span><br></pre></td></tr></table></figure></p><p>需要注意的是：函数名称前面一定要带上数据库名称。</p><h2 id="3-函数相关的HQL语句"><a href="#3-函数相关的HQL语句" class="headerlink" title="3. 函数相关的HQL语句"></a>3. 函数相关的HQL语句</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">-- 查看所有函数(内置函数+自定义函数)</span><br><span class="line">show functions;</span><br><span class="line">-- 查看某个函数的使用说明</span><br><span class="line">describe function function_name;</span><br><span class="line">-- 创建临时自定义函数</span><br><span class="line">create temporary function function_name as class_name;</span><br><span class="line">-- 删除临时自定义函数</span><br><span class="line">drop temporary function [if exists] function_name;</span><br><span class="line">-- 创建永久自定义函数</span><br><span class="line">create function [db_name.]function_name as class_name</span><br><span class="line">  [using jar|file|archive &apos;file_uri&apos; [, jar|file|archive &apos;file_uri&apos;] ];</span><br><span class="line">-- 删除永久自定义函数</span><br><span class="line">drop function [if exists] function_name;</span><br><span class="line">-- 重载函数</span><br><span class="line">reload function;</span><br></pre></td></tr></table></figure><h2 id="4-扩展与延伸"><a href="#4-扩展与延伸" class="headerlink" title="4. 扩展与延伸"></a>4. 扩展与延伸</h2><p>Hive自定义函数的扩展，不仅有UDF（User-Defined Functions），还有UDAF（User-Defined Aggregate Functions）和UDTF（User-Defined Table-Generating Functions），详情请参考官方说明。<br>另外，如果数据处理在函数级别不能解决，还可以借助 <code>TRANSFORM</code> 自定义Map和Reduce函数。</p><h2 id="5-参考"><a href="#5-参考" class="headerlink" title="5. 参考"></a>5. 参考</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins" target="_blank" rel="noopener">Creating Custom UDFs</a><br><a href="https://blog.csdn.net/qq_32653877/article/details/87182898" target="_blank" rel="noopener">Java编写Hive的UDF</a><br><a href="http://chaozi204.github.io/blog/hive-udf-deploy/" target="_blank" rel="noopener">Hive UDF 部署方式小结</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/GenericUDAFCaseStudy" target="_blank" rel="noopener">Writing GenericUDAFs</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Transform" target="_blank" rel="noopener">Hive’s Transform functionality</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Hive自带了许多内置函数（Built-in Functions），方便数据的处理分析。可是，有时候内置函数无法满足需求，这就需要自定义函数（User-Defined Functions , UDF）来实现想要的功能。&lt;br&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jordenbruce.com/categories/Hive/"/>
    
    
      <category term="udf" scheme="https://jordenbruce.com/tags/udf/"/>
    
  </entry>
  
  <entry>
    <title>Hive分区表</title>
    <link href="https://jordenbruce.com/2019/03/04/hive-partition/"/>
    <id>https://jordenbruce.com/2019/03/04/hive-partition/</id>
    <published>2019-03-04T14:57:21.000Z</published>
    <updated>2019-09-22T09:10:43.826Z</updated>
    
    <content type="html"><![CDATA[<p>分区作为Hive数据的一种组织形式，每个表可以有一个或多个分区键，用于确定数据如何被存储；例如，带有日期分区列ds的表T具有存储在HDFS中的<code>&lt;table location&gt;/ds=&lt;date&gt;</code>目录中的特定日期的数据文件。分区允许Hive根据查询条件选择要扫描的分区数据，比如一个需要访问T表中满足<code>T.ds=&#39;2008-09-01&#39;</code>条件的查询，Hive只需扫描HDFS中<code>&lt;table location&gt;/ds=2008-09-01/</code>目录中的文件即可。<br><a id="more"></a></p><h2 id="1-分区表操作语句"><a href="#1-分区表操作语句" class="headerlink" title="1. 分区表操作语句"></a>1. 分区表操作语句</h2><p>1) 新建分区表<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">create table if not exists default.dws_bhv_user_active_di (</span><br><span class="line">     imei           string comment &apos;设备号&apos;</span><br><span class="line">    ,act_cnt        bigint comment &apos;活跃次数&apos;</span><br><span class="line">    ,etl_time       string comment &apos;数据仓库更新时间&apos;</span><br><span class="line">)</span><br><span class="line">comment &apos;活跃设备的日增量&apos;</span><br><span class="line">partitioned by (</span><br><span class="line">    dt string comment &apos;日期分区&apos;</span><br><span class="line">)</span><br><span class="line">stored as parquet</span><br><span class="line">tblproperties(&apos;parquet.compression&apos;=&apos;SNAPPY&apos;)</span><br><span class="line">;</span><br></pre></td></tr></table></figure></p><p>2) 查询所有分区<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show partitions default.dws_bhv_user_active_di;</span><br></pre></td></tr></table></figure></p><p>3) 添加分区<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table default.dws_bhv_user_active_di add if not exists partition (dt=&apos;2019-03-04&apos;);</span><br></pre></td></tr></table></figure></p><p>4) 删除分区<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter table default.dws_bhv_user_active_di drop if exists partition (dt=&apos;2019-03-04&apos;);</span><br></pre></td></tr></table></figure></p><p>5) 清空分区数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">truncate table default.dws_bhv_user_active_di partition (dt=&apos;2019-03-04&apos;);</span><br></pre></td></tr></table></figure></p><p>6) 重写分区数据<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table default.dws_bhv_user_active_di partition (dt=&apos;2019-03-05&apos;)</span><br><span class="line">select imei,act_cnt,etl_time from default.dws_bhv_user_active_di</span><br><span class="line">where dt = &apos;2019-03-04&apos;;</span><br></pre></td></tr></table></figure></p><p>7) 修复分区<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">msck table default.dws_bhv_user_active_di;</span><br></pre></td></tr></table></figure></p><h2 id="2-静态分区与动态分区"><a href="#2-静态分区与动态分区" class="headerlink" title="2. 静态分区与动态分区"></a>2. 静态分区与动态分区</h2><p>2.1) 术语</p><ul><li>静态分区（SP）列：在涉及多个分区列的<code>DML/DDL</code>中，其值在COMPILE TIME（由用户给出）处已知的列。</li><li>动态分区（DP）列：其值仅在执行时已知的列。</li></ul><p>2.2) 语法</p><p>在partition子句中，DP列的指定方式与SP列相同。唯一的区别是DP列没有值，而SP列有值。在partition子句中，我们需要指定所有分区列，即使它们都是DP列。<br>在<code>INSERT...SELECT...</code>查询中，动态分区列必须在SELECT语句的列中最后指定，并且与它们在<code>PARTITION()</code>子句中出现的顺序相同。</p><p>2.3) 动态分区写入</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table default.dws_bhv_user_active_di partition (dt)</span><br><span class="line">select imei</span><br><span class="line">      ,act_cnt</span><br><span class="line">      ,etl_time</span><br><span class="line">      ,dt</span><br><span class="line">from default.dws_bhv_user_active_di</span><br><span class="line">where dt between &apos;2019-03-04&apos; and &apos;2019-03-05&apos;</span><br><span class="line">;</span><br></pre></td></tr></table></figure><p>2.4) 动态分区的参数</p><table><thead><tr><th>重要级别</th><th>参数名</th><th>默认值</th></tr></thead><tbody><tr><td>高</td><td>hive.exec.dynamic.partition</td><td>true</td></tr><tr><td>高</td><td>hive.exec.dynamic.partition.mode</td><td>strict</td></tr><tr><td>中</td><td>hive.exec.max.dynamic.partitions.pernode</td><td>100</td></tr><tr><td>中</td><td>hive.exec.max.dynamic.partitions</td><td>1000</td></tr><tr><td>中</td><td>hive.exec.max.created.files</td><td>100000</td></tr><tr><td>低</td><td>hive.error.on.empty.partition</td><td>false</td></tr></tbody></table><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/Design" target="_blank" rel="noopener">Hive Architecture Overview</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL" target="_blank" rel="noopener">Hive Data Definition Language</a><br><a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DML" target="_blank" rel="noopener">Hive DML: Dynamic Partition Inserts</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分区作为Hive数据的一种组织形式，每个表可以有一个或多个分区键，用于确定数据如何被存储；例如，带有日期分区列ds的表T具有存储在HDFS中的&lt;code&gt;&amp;lt;table location&amp;gt;/ds=&amp;lt;date&amp;gt;&lt;/code&gt;目录中的特定日期的数据文件。分区允许Hive根据查询条件选择要扫描的分区数据，比如一个需要访问T表中满足&lt;code&gt;T.ds=&amp;#39;2008-09-01&amp;#39;&lt;/code&gt;条件的查询，Hive只需扫描HDFS中&lt;code&gt;&amp;lt;table location&amp;gt;/ds=2008-09-01/&lt;/code&gt;目录中的文件即可。&lt;br&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jordenbruce.com/categories/Hive/"/>
    
    
      <category term="partition" scheme="https://jordenbruce.com/tags/partition/"/>
    
  </entry>
  
  <entry>
    <title>HQL内存溢出的参数调优</title>
    <link href="https://jordenbruce.com/2019/02/25/hive-oom/"/>
    <id>https://jordenbruce.com/2019/02/25/hive-oom/</id>
    <published>2019-02-24T17:26:20.000Z</published>
    <updated>2019-09-22T09:08:37.634Z</updated>
    
    <content type="html"><![CDATA[<p>我们在使用Hive进行ETL开发的过程中，关注更多的是使用HQL语言来准确地表达业务逻辑，而很少考虑到Hive对HQL语句的执行情况。当你辛辛苦苦地码完，将HQL语句扔给Hive去执行时，就有可能出现各种各样的报错，而其中一种比较常见的错误就是内存溢出（OOM，out of memory），通俗地讲就是内存不够。<br><a id="more"></a></p><h2 id="1-写在前面"><a href="#1-写在前面" class="headerlink" title="1. 写在前面"></a>1. 写在前面</h2><p>本文采用的软件版本如下：</p><ul><li>hive-2.0.1</li><li>hadoop-2.7.2</li></ul><p>hive使用MapReduce执行引擎，hadoop使用Yarn进行资源调度。</p><p>下文将从客户端提交HQL语句开始，Hive生成物理执行计划、Yarn资源分配、MapReduce执行，到执行结束，三个重点过程进行阐述，先理论再参数，希望OOM参数调优的问题得到收敛。</p><h2 id="2-Hive生成物理执行计划"><a href="#2-Hive生成物理执行计划" class="headerlink" title="2. Hive生成物理执行计划"></a>2. Hive生成物理执行计划</h2><p>先给出官网上关于Hive架构的经典流程图：</p><p><img src="https://i.loli.net/2019/02/24/5c72ad01e0c56.png" alt="Hive架构"></p><p>从这张图中，我们只需要明白一点即可：客户端提交的HQL语句，在Hive端的最终输出是物理执行计划，或者说是Job的有向无环图（a DAG of stages）。主要包括三种操作：</p><ul><li>MapReduce作业（a map/reduce job）</li><li>元数据操作（a metadata operation）</li><li>HDFS操作（an operation on HDFS）</li></ul><p>需要注意的是：这个过程主要是Hive优化器的执行，没有相关参数去控制内存的使用。当然，对于某些HQL语句适当地设置一些参数，可以得到更优的物理执行计划。比如常见的Map Join参数<code>hive.auto.convert.join</code>等。</p><h2 id="3-Yarn资源分配"><a href="#3-Yarn资源分配" class="headerlink" title="3. Yarn资源分配"></a>3. Yarn资源分配</h2><p>YARN是对Mapreduce V1重构得到的，有时候也成为MapReduce V2。由Hive生成物理执行计划，其中的MapReduce作业提交给Yarn来执行，详细的执行过程如下：</p><p><img src="https://i.loli.net/2019/02/24/5c72b4b3294ea.jpg" alt="MapReduce在Yarn下执行过程"></p><p>从上图可以看出，Yarn（以Container方式分配）控制着NodeManager、ApplicationMaster、Map和Reduce的内存使用，相关的内存参数有：</p><table><thead><tr><th>重要级别</th><th>参数名</th><th>默认值</th></tr></thead><tbody><tr><td>中</td><td>yarn.nodemanager.resource.memory-mb</td><td>8192</td></tr><tr><td>中</td><td>yarn.scheduler.minimum-allocation-mb</td><td>1024</td></tr><tr><td>中</td><td>yarn.scheduler.maximum-allocation-mb</td><td>8192</td></tr><tr><td>中</td><td>yarn.scheduler.increment-allocation-mb</td><td>1024</td></tr><tr><td>高</td><td>yarn.app.mapreduce.am.resource.mb</td><td>1536</td></tr><tr><td>中</td><td>yarn.app.mapreduce.am.command-opts</td><td>-Xmx1024m</td></tr><tr><td>低</td><td>yarn.app.mapreduce.am.admin-command-opts</td><td></td></tr><tr><td>中</td><td>yarn.nodemanager.vmem-pmem-ratio</td><td>2.1</td></tr><tr><td>低</td><td>yarn.nodemanager.pmem-check-enabled</td><td>true</td></tr><tr><td>低</td><td>yarn.nodemanager.vmem-check-enabled</td><td>true</td></tr><tr><td>高</td><td>mapreduce.reduce.memory.mb</td><td>1024</td></tr><tr><td>中</td><td>mapreduce.reduce.java.opts</td><td></td></tr><tr><td>高</td><td>mapreduce.map.memory.mb</td><td>1024</td></tr><tr><td>中</td><td>mapreduce.map.java.opts</td></tr></tbody></table><h3 id="3-1-基础"><a href="#3-1-基础" class="headerlink" title="3.1 基础"></a>3.1 基础</h3><ul><li>NodeManager可用于分配的最大内存是yarn.nodemanager.resource.memory-mb；</li><li>Yarn的ResourceManger（简称RM）通过逻辑上的队列分配内存等资源给application，默认情况下RM允许最大AM申请Container资源为8192MB(“yarn.scheduler.maximum-allocation-mb“)，默认情况下的最小分配资源为1024M(“yarn.scheduler.minimum-allocation-mb“)，如果参数中需要的资源在此范围之外，在任务submit的时候会被直接拒绝掉；</li><li>AM只能以增量 (“yarn.scheduler.minimum-allocation-mb”) + (“yarn.scheduler.increment-allocation-mb”) 规整每个task需要的内存，并且申请的内存只能在（”yarn.scheduler.minimum-allocation-mb“）和(“yarn.scheduler.maximum-allocation-mb“) 的范围内向RM申请资源；</li><li>每个Map任务或Reduce任务分配的内存为mapreduce.reduce.memory.mb或mapreduce.map.memory.mb；</li></ul><h3 id="3-2-mapreduce-map-java-opts和mapreduce-map-memory-mb区别"><a href="#3-2-mapreduce-map-java-opts和mapreduce-map-memory-mb区别" class="headerlink" title="3.2 mapreduce.map.java.opts和mapreduce.map.memory.mb区别"></a>3.2 mapreduce.map.java.opts和mapreduce.map.memory.mb区别</h3><p>JVM进程跑在container中，mapreduce.map.java.opts能够通过Xmx设置JVM最大的heap的使用，一般设置为0.75倍的mapreduce.map.memory.mb ，因为需要为java code，非JVM内存使用等预留些空间；mapreduce.reduce.java.opts和mapreduce.reduce.memory.mb同理。</p><h3 id="3-3-虚拟内存"><a href="#3-3-虚拟内存" class="headerlink" title="3.3 虚拟内存"></a>3.3 虚拟内存</h3><p>默认的(“yarn.nodemanager.vmem-pmem-ratio“)设置为2.1，意味则map container或者reduce container分配的虚拟内存超过2.1倍的(“mapreduce.reduce.memory.mb“)或(“mapreduce.map.memory.mb“)就会被NM给KILL掉，如果 (“mapreduce.map.memory.mb”) 被设置为1536M那么总的虚拟内存为2.1*1536=3225.6MB</p><h3 id="3-4-内存检查"><a href="#3-4-内存检查" class="headerlink" title="3.4 内存检查"></a>3.4 内存检查</h3><p>如果虚拟内存检查被打开（yarn.nodemanager.vmem-check-enabled默认情况下为true），然后YARN将把抽取出来的容器及其子进程的VSIZE加起来和容器最大允许使用的虚拟内存进行比较。最大允许使用的虚拟内存是容器最大可使用的物理内存乘以 yarn.nodemanager.vmem-pmem-ratio（默认值是2.1）。所以，如果你的YARN容器配置的最大可使用物理内存为2GB，然后我们乘以 2.1 得到的就是容器最大可用的虚拟内存 4.2G 。</p><p>如果物理内存检查被打开（yarn.nodemanager.pmem-check-enabled默认情况为true），然后YARN将把抽取出来的容器及其子进程的RSS加起来和容器最大允许使用的物理内存进行比较。</p><p>如果物理内存或者虚拟内存其中一个的使用大于最大允许使用的，YARN将会被这个容器杀掉。</p><h3 id="3-5-参数全局图"><a href="#3-5-参数全局图" class="headerlink" title="3.5 参数全局图"></a>3.5 参数全局图</h3><p>参数多不要慌，下面来张图梳理下：</p><p><img src="https://i.loli.net/2019/02/25/5c72c07905cf3.jpg" alt="Yarn内存参数"></p><h2 id="4-MapReduce执行"><a href="#4-MapReduce执行" class="headerlink" title="4. MapReduce执行"></a>4. MapReduce执行</h2><p>MapReduce作业的重点是Shuffle过程，还是老套路，先给出官网上关于这个过程的经典流程图：</p><p><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/pNFrlaAqE9YU.png" alt="Shuffle过程"></p><p>当Map任务或Reduce任务以Container方式申请到相应的内存资源后，就进入了实际的执行过程中，其中涉及的参数有：</p><table><thead><tr><th>重要级别</th><th>参数名</th><th>默认值</th></tr></thead><tbody><tr><td>高</td><td>mapreduce.job.maps</td><td>2</td></tr><tr><td>中</td><td>mapreduce.input.fileinputformat.split.minsize</td><td>1</td></tr><tr><td>中</td><td>dfs.blocksize</td><td>134217728</td></tr><tr><td>高</td><td>mapreduce.job.reduces</td><td>1</td></tr><tr><td>中</td><td>mapreduce.task.io.sort.mb</td><td>100</td></tr><tr><td>中</td><td>mapreduce.map.sort.spill.percent</td><td>0.80</td></tr><tr><td>中</td><td>mapreduce.task.io.sort.factor</td><td>10</td></tr><tr><td>中</td><td>mapreduce.map.output.compress</td><td>false</td></tr><tr><td>中</td><td>mapreduce.map.output.compress.codec</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>低</td><td>mapreduce.job.reduce.slowstart.completedmaps</td><td>0.05</td></tr><tr><td>中</td><td>mapreduce.reduce.shuffle.parallelcopies</td><td>5</td></tr><tr><td>高</td><td>mapreduce.reduce.shuffle.input.buffer.percent</td><td>0.70</td></tr></tbody></table><p>为了更好地理解每个参数作用的阶段，建议先阅读 <a href="https://jordenbruce.com/2019/02/19/hadoop-shuffle/">MapReduce之Shuffle过程详解</a>。</p><h3 id="4-1-Map任务"><a href="#4-1-Map任务" class="headerlink" title="4.1 Map任务"></a>4.1 Map任务</h3><p>（1）split分片：split是在逻辑上对输入数据进行的分片，并不会在磁盘上将其切分成分片进行存储。每个split都作为一个独立单位分配给一个map task去处理。决定split分片大小的参数有：</p><ul><li>mapreduce.job.maps</li><li>mapreduce.input.fileinputformat.split.minsize</li><li>dfs.blocksize (会话级别不可设置)</li></ul><p>（2）内存缓冲区：经过map处理后的键值对，不会立马写入磁盘，而是暂时保存在内存中的MapOutputBuffe内部的环形数据缓冲区，设置缓冲区大小的参数有：</p><ul><li>mapreduce.task.io.sort.mb</li><li>mapreduce.map.sort.spill.percent</li></ul><p>（3）压缩：map端在写磁盘的时候采用压缩的方式将map的输出结果进行压缩是一个减少网络开销很有效的方法。其实，在Hadoop中早已为我们提供了一些压缩算法的实现，直接配置参数即可。</p><ul><li>mapreduce.map.output.compress</li><li>mapreduce.map.output.compress.codec</li></ul><h3 id="4-2-Reduce任务"><a href="#4-2-Reduce任务" class="headerlink" title="4.2 Reduce任务"></a>4.2 Reduce任务</h3><p>（1）文件拷贝：默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的 <code>mapreduce.job.reduce.slowstart.completedmaps</code> (默认为0.05) 后，ApplicationMaster便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动 <code>mapred.reduce.parallel.copies</code> (默认为5) 个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上。</p><p>（2）内存缓冲区：这个内存缓冲区大小的控制就不像map那样可以通过 <code>mapreduce.task.io.sort.mb</code> 来设定了，而是通过另外一个参数来设置：<code>mapred.job.shuffle.input.buffer.percent</code>（default 0.7）， 这个参数其实是一个百分比，意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × maxHeap of reduce task。</p><h2 id="5-HQL语句的日志输出"><a href="#5-HQL语句的日志输出" class="headerlink" title="5. HQL语句的日志输出"></a>5. HQL语句的日志输出</h2><p>经过漫长的理论铺垫，终于要到解决问题的时候了，HQL语句的内存溢出主要从日志分析开始。</p><ul><li>HQL语句的执行过程中，有哪些日志输出呢？分别存放在什么地方？如何分析出有用信息？</li><li>内存溢出包括哪几类？典型日志有哪些？调优什么参数可以解决？</li><li>小文件太多是如何产生的？调优什么参数可以合并小文件？</li></ul><p>等等一系列有关问题，且听下回分解。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/Design" target="_blank" rel="noopener">Hive Architecture Overview</a><br><a href="https://segmentfault.com/a/1190000003777237" target="_blank" rel="noopener">Yarn下Mapreduce的内存参数理解</a><br><a href="https://jordenbruce.com/2019/02/19/hadoop-shuffle/">MapReduce之Shuffle过程详解</a><br><a href="https://blog.csdn.net/lazythinker/article/details/75497774" target="_blank" rel="noopener">HIVE参数调优（汇总）</a><br><a href="https://blog.csdn.net/aijiudu/article/details/72353510" target="_blank" rel="noopener">MapReduce过程详解及其性能优化</a><br><a href="https://my.oschina.net/OttoWu/blog/816049" target="_blank" rel="noopener">hadoop fair scheduler 的坑</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在使用Hive进行ETL开发的过程中，关注更多的是使用HQL语言来准确地表达业务逻辑，而很少考虑到Hive对HQL语句的执行情况。当你辛辛苦苦地码完，将HQL语句扔给Hive去执行时，就有可能出现各种各样的报错，而其中一种比较常见的错误就是内存溢出（OOM，out of memory），通俗地讲就是内存不够。&lt;br&gt;
    
    </summary>
    
      <category term="Hive" scheme="https://jordenbruce.com/categories/Hive/"/>
    
    
      <category term="oom" scheme="https://jordenbruce.com/tags/oom/"/>
    
  </entry>
  
  <entry>
    <title>YARN架构详解</title>
    <link href="https://jordenbruce.com/2019/02/21/hadoop-yarn/"/>
    <id>https://jordenbruce.com/2019/02/21/hadoop-yarn/</id>
    <published>2019-02-20T16:36:20.000Z</published>
    <updated>2019-09-22T09:09:00.580Z</updated>
    
    <content type="html"><![CDATA[<p>YARN（Yet Another Resource Negotiator）是一个通用的资源管理平台，可为各类计算框架提供资源的管理和调度。 其核心出发点是为了分离资源管理与作业调度/监控，实现分离的做法是拥有一个全局的资源管理器（ResourceManager，RM），以及每个应用程序对应一个的应用管理器（ApplicationMaster，AM），应用程序由一个作业（Job）或者Job的有向无环图（DAG）组成。<br><a id="more"></a></p><p>YARN可以将多种计算框架(如离线处理MapReduce、在线处理的Storm、迭代式计算框架Spark、流式处理框架S4等) 部署到一个公共集群中，共享集群的资源。并提供如下功能：</p><ul><li><p><strong>资源的统一管理和调度</strong>：集群中所有节点的资源(内存、CPU、磁盘、网络等)抽象为Container。计算框架需要资源进行运算任务时需要向YARN申请Container， YARN按照特定的策略对资源进行调度进行Container的分配。</p></li><li><p><strong>资源隔离</strong>：YARN使用了轻量级资源隔离机制Cgroups进行资源隔离以避免相互干扰，一旦Container使用的资源量超过事先定义的上限值，就将其杀死。</p></li></ul><p>YARN是对Mapreduce V1重构得到的，有时候也成为MapReduce V2。 </p><p>YARN可以看成一个云操作系统，由一个ResourceManager和多个NodeManager组成， 它负责管理所有NodeManger上多维度资源， 并以Container(启动一个Container相当于启动一个进程)方式分配给应用程序启动ApplicationMaster(相当于主进程中运行逻辑) 或运行ApplicationMaster切分的各Task(相当于子进程中运行逻辑)。</p><h2 id="YARN体系架构"><a href="#YARN体系架构" class="headerlink" title="YARN体系架构"></a>YARN体系架构</h2><p>YARN架构如下图所示：<br><img src="https://i.loli.net/2019/02/20/5c6d021102002.png" alt="YARN架构"></p><p>YARN总体上是Master/Slave结构，主要由ResourceManager、NodeManager、 ApplicationMaster和Container等几个组件构成。</p><ul><li><p><strong>ResourceManager(RM)</strong>：负责对各NM上的资源进行统一管理和调度。将AM分配空闲的Container运行并监控其运行状态。对AM申请的资源请求分配相应的空闲Container。主要由两个组件构成：调度器和应用程序管理器：</p><ol><li>调度器(Scheduler)：调度器根据容量、队列等限制条件（如每个队列分配一定的资源，最多执行一定数量的作业等），将系统中的资源分配给各个正在运行的应用程序。调度器仅根据各个应用程序的资源需求进行资源分配，而资源分配单位是Container，从而限定每个任务使用的资源量。Shceduler不负责监控或者跟踪应用程序的状态，也不负责任务因为各种原因而需要的重启（由ApplicationMaster负责）。总之，调度器根据应用程序的资源要求，以及集群机器的资源情况，为应用程序分配封装在Container中的资源。<br>调度器是可插拔的，例如CapacityScheduler、FairScheduler。具体看下文的调度算法。</li><li>应用程序管理器(Applications Manager)：应用程序管理器负责管理整个系统中所有应用程序，包括应用程序提交、与调度器协商资源以启动AM、监控AM运行状态并在失败时重新启动等，跟踪分给的Container的进度、状态也是其职责。</li></ol></li><li><p><strong>NodeManager (NM)</strong>：NM是每个节点上的资源和任务管理器。它会定时地向RM汇报本节点上的资源使用情况和各个Container的运行状态；同时会接收并处理来自AM的Container 启动/停止等请求。</p></li><li><p><strong>ApplicationMaster (AM)</strong>：用户提交的应用程序均包含一个AM，负责应用的监控，跟踪应用执行状态，重启失败任务等。ApplicationMaster是应用框架，它负责向ResourceManager协调资源，并且与NodeManager协同工作完成Task的执行和监控。MapReduce就是原生支持的一种框架，可以在YARN上运行Mapreduce作业。有很多分布式应用都开发了对应的应用程序框架，用于在YARN上运行任务，例如Spark，Storm等。如果需要，我们也可以自己写一个符合规范的YARN application。</p></li><li><p><strong>Container</strong>：Container是YARN中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container 表示的。 YARN会为每个任务分配一个Container且该任务只能使用该Container中描述的资源。</p></li></ul><h2 id="YARN应用工作流程"><a href="#YARN应用工作流程" class="headerlink" title="YARN应用工作流程"></a>YARN应用工作流程</h2><p>如下图所示用户向YARN中提交一个应用程序后，YARN将分两个阶段运行该应用程序：</p><ul><li>启动AM ，如下步骤1~3；</li><li>由AM创建应用程序为它申请资源并监控它的整个运行过程，直到运行完成，如下步骤4~7。</li></ul><p><img src="https://i.loli.net/2019/02/20/5c6d03e204bfc.png" alt="YARN工作流程"></p><ol><li><p>用户向YARN中提交应用程序，其中包括AM程序、启动AM的命令、命令参数、用户程序等；事实上，需要准确描述运行ApplicationMaster的unix进程的所有信息。提交工作通常由YarnClient来完成。</p></li><li><p>RM为该应用程序分配第一个Container，并与对应的NM通信，要求它在这个Container中启动AM；</p></li><li><p>AM首先向RM注册，这样用户可以直接通过RM査看应用程序的运行状态，运行状态通过 AMRMClientAsync.CallbackHandler的getProgress() 方法来传递给RM。 然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4〜7；</p></li><li><p>AM采用轮询的方式通过RPC协议向RM申请和领取资源；资源的协调通过 AMRMClientAsync异步完成,相应的处理方法封装在AMRMClientAsync.CallbackHandler中。</p></li><li><p>—旦AM申请到资源后，便与对应的NM通信，要求它启动任务；通常需要指定一个ContainerLaunchContext，提供Container启动时需要的信息。</p></li><li><p>NM为任务设置好运行环境(包括环境变量、JAR包、二进制程序等)后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务；</p></li><li><p>各个任务通过某个RPC协议向AM汇报自己的状态和进度，以让AM随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务；ApplicationMaster与NM的通信通过NMClientAsync object来完成，容器的所有事件通过NMClientAsync.CallbackHandler来处理。例如启动、状态更新、停止等。</p></li><li><p>应用程序运行完成后，AM向RM注销并关闭自己。</p></li></ol><h2 id="YARN资源调度模型"><a href="#YARN资源调度模型" class="headerlink" title="YARN资源调度模型"></a>YARN资源调度模型</h2><p>YARN提供了一个资源管理平台能够将集群中的资源统一进行管理。所有节点上的多维度资源都会根据申请抽象为一个个Container。</p><p>YARN采用了双层资源调度模型：</p><ul><li><p>RM中的资源调度器将资源分配给各个AM：资源分配过程是异步的。资源调度器将资源分配给一个应用程序后，它不会立刻push给对应的AM，而是暂时放到一个缓冲区中，等待AM通过周期性的心跳主动来取；</p></li><li><p>AM领取到资源后再进一步分配给它内部的各个任务：不属于YARN平台的范畴，由用户自行实现。</p></li></ul><p>也就是说，ResourceManager分配集群资源的时候，以抽象的Container形式分配给各应用程序，至于应用程序的子任务如何使用这些资源，由应用程序自行决定。</p><p>YARN目前采用的资源分配算法有三种。但真实的调度器实现中还对算法做了一定程度的优化。</p><ol><li><p>Capacity Scheduler：该调度器用于在共享、多租户（multi-tenant）的集群环境中运行Hadoop应用，对运营尽可能友好的同时最大化吞吐量和效用。 </p></li><li><p>Fair Scheduler：公平调度FAIR，该算法的思想是尽可能地公平调度，即已分配资源量少的优先级高。也就是说，在考虑如何分配资源时，调度器尽可能使得每个应用程序都能够得到大致相当的资源。默认情况下，公平性只通过内存来衡量，但是可以配置成内存和CPU。 </p></li></ol><h2 id="YARN的资源管理"><a href="#YARN的资源管理" class="headerlink" title="YARN的资源管理"></a>YARN的资源管理</h2><ol><li><p>资源调度和隔离是yarn作为一个资源管理系统，最重要且最基础的两个功能。资源调度由resourcemanager完成，而资源隔离由各个nodemanager实现。</p></li><li><p>Resourcemanager将某个nodemanager上资源分配给任务（这就是所谓的“资源调度”）后，nodemanager需按照要求为任务提供相应的资源，甚至保证这些资源应具有独占性，为任务运行提供基础和保证，这就是所谓的资源隔离。</p></li><li><p>当谈及到资源时，我们通常指内存、cpu、io三种资源。Hadoop yarn目前为止仅支持cpu和内存两种资源管理和调度。</p></li><li><p>内存资源多少决定任务的生死，如果内存不够，任务可能运行失败；相比之下，cpu资源则不同，它只会决定任务的快慢，不会对任务的生死产生影响。</p></li></ol><p>以上内容来自：<br><a href="https://blog.csdn.net/bingduanlbd/article/details/51880019" target="_blank" rel="noopener">理解Hadoop YARN架构</a><br><a href="http://www.cnblogs.com/wcwen1990/p/6737985.html" target="_blank" rel="noopener">YARN架构设计详解</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;YARN（Yet Another Resource Negotiator）是一个通用的资源管理平台，可为各类计算框架提供资源的管理和调度。 其核心出发点是为了分离资源管理与作业调度/监控，实现分离的做法是拥有一个全局的资源管理器（ResourceManager，RM），以及每个应用程序对应一个的应用管理器（ApplicationMaster，AM），应用程序由一个作业（Job）或者Job的有向无环图（DAG）组成。&lt;br&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://jordenbruce.com/categories/Hadoop/"/>
    
    
      <category term="yarn" scheme="https://jordenbruce.com/tags/yarn/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce之Shuffle过程详解</title>
    <link href="https://jordenbruce.com/2019/02/19/hadoop-shuffle/"/>
    <id>https://jordenbruce.com/2019/02/19/hadoop-shuffle/</id>
    <published>2019-02-19T13:44:20.000Z</published>
    <updated>2019-09-22T09:09:44.943Z</updated>
    
    <content type="html"><![CDATA[<p>MapReduce计算模型一般包括两个重要的阶段：Map是映射，负责数据的过滤分发，将原始数据转化为键值对；Reduce是规约，将具有相同key值的value进行处理后再输出新的键值对作为最终结果。为了让Reduce可以并行处理Map的结果，必须对Map的输出进行一定的排序与分割，然后再交给对应的Reduce，而这个将Map输出进行进一步整理并交给Reduce的过程就是Shuffle。<br><a id="more"></a></p><h2 id="总述"><a href="#总述" class="headerlink" title="总述"></a>总述</h2><p>Shuffle过程是MapReduce的核心，也被称为奇迹发生的地方。要想理解MapReduce，Shuffle是必须要了解的。这里先给出官网上关于这个过程的经典流程图：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/pNFrlaAqE9YU.png" alt="Shuffle过程"><br>上图是把MapReduce过程分为两个部分，而实际上从两边的Map和Reduce到中间的那一大块都属于Shuffle过程，也就是说，Shuffle过程有一部分是在Map端，有一部分是在Reduce端，下文也将会分两部分来介绍Shuffle过程。</p><p>对于Hadoop集群，当我们在运行作业时，大部分的情况下，map task与reduce task的执行是分布在不同的节点上的，因此，很多情况下，reduce执行时需要跨节点去拉取其他节点上的map task结果，这样造成了集群内部的网络资源消耗很严重，而且在节点的内部，相比于内存，磁盘IO对性能的影响是非常严重的。如果集群中运行的作业有很多，那么task的执行对于集群内部网络的资源消费非常大。因此，我们对于MapRedue作业Shuffle过程的期望是：</p><ul><li>完整地从map task端拉取数据到Reduce端；</li><li>在跨节点拉取数据时，尽可能地减少对带宽的不必要消耗；</li><li>减少磁盘IO对task执行的影响。</li></ul><h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>在进行海量数据处理时，外存文件数据I/O访问会成为一个制约系统性能的瓶颈，因此，Hadoop的Map过程实现的一个重要原则就是：计算靠近数据，这里主要指两个方面：</p><ol><li>代码靠近数据：<ul><li>原则：本地化数据处理（locality），即一个计算节点尽可能处理本地磁盘上所存储的数据；</li><li>尽量选择数据所在DataNode启动Map任务；</li><li>这样可以减少数据通信，提高计算效率；</li></ul></li><li>数据靠近代码：<ul><li>当本地没有数据处理时，尽可能从同一机架或最近其他节点传输数据进行处理（host选择算法）。</li></ul></li></ol><p>下面，我们分块去介绍Hadoop的Map过程，map的经典流程图如下：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/Hc0RIDhvW7CU.jpg" alt="map-shuffle"></p><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><ol><li>map task只读取split分片，split与block（hdfs的最小存储单位，默认为64MB）可能是一对一也能是一对多，但是对于一个split只会对应一个文件的一个block或多个block，不允许一个split对应多个文件的多个block；</li><li>这里切分和输入数据的时会涉及到InputFormat的文件切分算法和host选择算法。</li></ol><p>文件切分算法，主要用于确定InputSplit的个数以及每个InputSplit对应的数据段。FileInputFormat以文件为单位切分生成InputSplit，对于每个文件，由以下三个属性值决定其对应的InputSplit的个数：</p><ul><li>goalSize：它是根据用户期望的InputSplit数目计算出来的，即totalSize/numSplits。其中，totalSize为文件的总大小；numSplits为用户设定的Map Task个数，默认情况下是1；</li><li>minSize：InputSplit的最小值，由配置参数mapred.min.split.size确定，默认是1；</li><li>blockSize：文件在hdfs中存储的block大小，不同文件可能不同，默认是64MB。</li></ul><p>这三个参数共同决定InputSplit的最终大小，计算方法如下：<br><code>splitSize = max{minSize, min{gogalSize,blockSize}}</code></p><p>细节请参考《<a href="https://blog.csdn.net/xingliang_li/article/details/53285447" target="_blank" rel="noopener">FileInputFormat类中split切分算法和host选择算法介绍</a>》</p><h3 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h3><ul><li>作用：将map的结果发送到相应的reduce端，总的partition的数目等于reducer的数量。</li><li>实现功能：<ol><li>map输出的是key/value对，决定于当前的mapper的part交给哪个reduce的方法是：mapreduce提供的Partitioner接口，对key进行hash后，再以reducetask数量取模，然后到指定的job上（HashPartitioner，可以通过job.setPartitionerClass(MyPartition.class)自定义）。</li><li>然后将数据写入到内存缓冲区，缓冲区的作用是批量收集map结果，减少磁盘IO的影响。key/value对以及Partition的结果都会被写入缓冲区。在写入之前，key与value值都会被序列化成字节数组。</li></ol></li><li>要求：负载均衡，效率；</li></ul><h3 id="spill（溢写）：sort-amp-combiner"><a href="#spill（溢写）：sort-amp-combiner" class="headerlink" title="spill（溢写）：sort &amp; combiner"></a>spill（溢写）：sort &amp; combiner</h3><ul><li>作用：把内存缓冲区中的数据写入到本地磁盘，在写入本地磁盘时先按照partition、再按照key进行排序（quick sort）；</li><li>注意：<ol><li>这个spill是由另外单独的线程来完成，不影响往缓冲区写map结果的线程；</li><li>内存缓冲区默认大小限制为100MB，它有个溢写比例（spill.percent），默认为0.8，当缓冲区的数据达到阈值时，溢写线程就会启动，先锁定这80MB的内存，执行溢写过程，maptask的输出结果还可以往剩下的20MB内存中写，互不影响。然后再重新利用这块缓冲区，因此Map的内存缓冲区又叫做环形缓冲区（两个指针的方向不会变，下面会详述）；</li><li>在将数据写入磁盘之前，先要对要写入磁盘的数据进行一次排序操作，先按&lt;key,value,partition&gt;中的partition分区号排序，然后再按key排序，这个就是sort操作，最后溢出的小文件是分区的，且同一个分区内是保证key有序的；</li></ol></li></ul><p>combine：执行combine操作要求开发者必须在程序中设置了combine（程序中通过job.setCombinerClass(myCombine.class)自定义combine操作）。</p><ul><li>程序中有两个阶段可能会执行combine操作：<ol><li>map输出数据根据分区排序完成后，在写入文件之前会执行一次combine操作（前提是作业中设置了这个操作）；</li><li>如果map输出比较大，溢出文件个数大于3（此值可以通过属性min.num.spills.for.combine配置）时，在merge的过程（多个spill文件合并为一个大文件）中还会执行combine操作；</li></ol></li><li>combine主要是把形如&lt;aa,1&gt;,&lt;aa,2&gt;这样的key值相同的数据进行计算，计算规则与reduce一致，比如：当前计算是求key对应的值求和，则combine操作后得到&lt;aa,3&gt;这样的结果。</li><li>注意事项：不是每种作业都可以做combine操作的，只有满足以下条件才可以：<ol><li>reduce的输入输出类型都一样，因为combine本质上就是reduce操作；</li><li>计算逻辑上，combine操作后不会影响计算结果，像求和就不会影响；</li></ol></li></ul><h3 id="merge"><a href="#merge" class="headerlink" title="merge"></a>merge</h3><ul><li>merge过程：当map很大时，每次溢写会产生一个spill_file，这样会有多个spill_file，而最终的一个map task输出只有一个文件，因此，最终的结果输出之前会对多个中间过程进行多次溢写文件（spill_file）的合并，此过程就是merge过程。也即是，待Map Task任务的所有数据都处理完后，会对任务产生的所有中间数据文件做一次合并操作，以确保一个Map Task最终只生成一个中间数据文件。</li><li>注意：<ol><li>如果生成的文件太多，可能会执行多次合并，每次最多能合并的文件数默认为10，可以通过属性min.num.spills.for.combine配置；</li><li>多个溢出文件合并时，会进行一次排序，排序算法是多路归并排序；</li><li>是否还需要做combine操作，一是看是否设置了combine，二是看溢出的文件数是否大于等于3；</li><li>最终生成的文件格式与单个溢出文件一致，也是按分区顺序存储，并且输出文件会有一个对应的索引文件，记录每个分区数据的起始位置，长度以及压缩长度，这个索引文件名叫做file.out.index。</li></ol></li></ul><h3 id="内存缓冲区"><a href="#内存缓冲区" class="headerlink" title="内存缓冲区"></a>内存缓冲区</h3><ol><li>在Map Task任务的业务处理方法map()中，最后一步通过OutputCollector.collect(key,value)或context.write(key,value)输出Map Task的中间处理结果，在相关的collect(key,value)方法中，会调用Partitioner.getPartition(K2 key, V2 value, int numPartitions)方法获得输出的key/value对应的分区号(分区号可以认为对应着一个要执行Reduce Task的节点)，然后将&lt;key,value,partition&gt;暂时保存在内存中的MapOutputBuffe内部的环形数据缓冲区，该缓冲区的默认大小是100MB，可以通过参数io.sort.mb来调整其大小。</li><li>当缓冲区中的数据使用率达到一定阀值后，触发一次Spill操作，将环形缓冲区中的部分数据写到磁盘上，生成一个临时的Linux本地数据的spill文件；然后在缓冲区的使用率再次达到阀值后，再次生成一个spill文件。直到数据处理完毕，在磁盘上会生成很多的临时文件。</li><li>缓存有一个阀值比例配置，当达到整个缓存的这个比例时，会触发spill操作；触发时，map输出还会接着往剩下的空间写入，但是写满的空间会被锁定，数据溢出写入磁盘。当这部分溢出的数据写完后，空出的内存空间可以接着被使用，形成像环一样的被循环使用的效果，所以又叫做环形内存缓冲区；</li><li>MapOutputBuffe内部存数的数据采用了两个索引结构，涉及三个环形内存缓冲区。下来看一下两级索引结构：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/RSrtmYI28b5L.jpg" alt="MapOutputBuffer的两级索引结构"></li></ol><p>写入到缓冲区的数据采取了压缩算法 <a href="http://www.cnblogs.com/edisonchou/p/4298423.html" target="_blank" rel="noopener">http://www.cnblogs.com/edisonchou/p/4298423.html</a><br>这三个环形缓冲区的含义分别如下：</p><ol><li>kvoffsets缓冲区：也叫偏移量索引数组，用于保存key/value信息在位置索引 kvindices 中的偏移量。当 kvoffsets 的使用率超过 io.sort.spill.percent (默认为80%)后，便会触发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li><li>kvindices缓冲区：也叫位置索引数组，用于保存 key/value 在数据缓冲区 kvbuffer 中的起始位置。</li><li>kvbuffer即数据缓冲区：用于保存实际的 key/value 的值。默认情况下该缓冲区最多可以使用 io.sort.mb 的95%，当 kvbuffer 使用率超过 io.sort.spill.percent (默认为80%)后，便会出发一次 SpillThread 线程的“溢写”操作，也就是开始一次 Spill 阶段的操作。</li></ol><p>写入到本地磁盘时，对数据进行排序，实际上是对kvoffsets这个偏移量索引数组进行排序。</p><h2 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h2><p>Reduce过程的经典流程图如下：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190219/aUlSEGON9iXl.png" alt="reduce-shuffle"></p><h3 id="copy过程"><a href="#copy过程" class="headerlink" title="copy过程"></a>copy过程</h3><ul><li>作用：拉取数据；</li><li>过程：Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求map task所在的TaskTracker获取map task的输出文件。因为这时map task早已结束，这些文件就归TaskTracker管理在本地磁盘中。</li><li>默认情况下，当整个MapReduce作业的所有已执行完成的Map Task任务数超过Map Task总数的5%后，JobTracker便会开始调度执行Reduce Task任务。然后Reduce Task任务默认启动mapred.reduce.parallel.copies(默认为5）个MapOutputCopier线程到已完成的Map Task任务节点上分别copy一份属于自己的数据。 这些copy的数据会首先保存的内存缓冲区中，当内冲缓冲区的使用率达到一定阀值后，则写到磁盘上。</li></ul><h4 id="内存缓冲区-1"><a href="#内存缓冲区-1" class="headerlink" title="内存缓冲区"></a>内存缓冲区</h4><ul><li>这个内存缓冲区大小的控制就不像map那样可以通过io.sort.mb来设定了，而是通过另外一个参数来设置：mapred.job.shuffle.input.buffer.percent（default 0.7）， 这个参数其实是一个百分比，意思是说，shuffile在reduce内存中的数据最多使用内存量为：0.7 × maxHeap of reduce task。</li><li>如果该reduce task的最大heap使用量（通常通过mapred.child.java.opts来设置，比如设置为-Xmx1024m）的一定比例用来缓存数据。默认情况下，reduce会使用其heapsize的70%来在内存中缓存数据。如果reduce的heap由于业务原因调整的比较大，相应的缓存大小也会变大，这也是为什么reduce用来做缓存的参数是一个百分比，而不是一个固定的值了。</li></ul><h3 id="merge过程"><a href="#merge过程" class="headerlink" title="merge过程"></a>merge过程</h3><ul><li>Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比 map 端的更为灵活，它基于 JVM 的heap size设置，因为 Shuffle 阶段 Reducer 不运行，所以应该把绝大部分的内存都给 Shuffle 用。</li><li>这里需要强调的是，merge 有三种形式：1)内存到内存 2)内存到磁盘 3)磁盘到磁盘。默认情况下第一种形式是不启用的。当内存中的数据量到达一定阈值，就启动内存到磁盘的 merge（图中的第一个merge，之所以进行merge是因为reduce端在从多个map端copy数据的时候，并没有进行sort，只是把它们加载到内存，当达到阈值写入磁盘时，需要进行merge） 。这和map端的很类似，这实际上就是溢写的过程，在这个过程中如果你设置有Combiner，它也是会启用的，然后在磁盘中生成了众多的溢写文件，这种merge方式一直在运行，直到没有 map 端的数据时才结束，然后才会启动第三种磁盘到磁盘的 merge （图中的第二个merge）方式生成最终的那个文件。</li><li>在远程copy数据的同时，Reduce Task在后台启动了两个后台线程对内存和磁盘上的数据文件做合并操作，以防止内存使用过多或磁盘生的文件过多。</li></ul><h3 id="reducer的输入文件"><a href="#reducer的输入文件" class="headerlink" title="reducer的输入文件"></a>reducer的输入文件</h3><ul><li>merge的最后会生成一个文件，大多数情况下存在于磁盘中，但是需要将其放入内存中。当reducer 输入文件已定，整个 Shuffle 阶段才算结束。然后就是 Reducer 执行，把结果放到 HDFS 上。</li></ul><p>以上内容来自：<a href="http://matt33.com/2016/03/02/hadoop-shuffle/" target="_blank" rel="noopener">MapReduce之Shuffle过程详述</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MapReduce计算模型一般包括两个重要的阶段：Map是映射，负责数据的过滤分发，将原始数据转化为键值对；Reduce是规约，将具有相同key值的value进行处理后再输出新的键值对作为最终结果。为了让Reduce可以并行处理Map的结果，必须对Map的输出进行一定的排序与分割，然后再交给对应的Reduce，而这个将Map输出进行进一步整理并交给Reduce的过程就是Shuffle。&lt;br&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="https://jordenbruce.com/categories/Hadoop/"/>
    
    
      <category term="mapreduce" scheme="https://jordenbruce.com/tags/mapreduce/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce执行过程详解</title>
    <link href="https://jordenbruce.com/2019/02/17/hadoop-mapreduce/"/>
    <id>https://jordenbruce.com/2019/02/17/hadoop-mapreduce/</id>
    <published>2019-02-17T14:57:51.000Z</published>
    <updated>2019-09-22T09:10:04.573Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分析MapReduce执行过程"><a href="#分析MapReduce执行过程" class="headerlink" title="分析MapReduce执行过程"></a>分析MapReduce执行过程</h2><p>MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。整个流程如图：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/ttzqIIqCPiXv.png" alt="MapReduce执行过程"></p><h3 id="Mapper任务的执行过程详解"><a href="#Mapper任务的执行过程详解" class="headerlink" title="Mapper任务的执行过程详解"></a>Mapper任务的执行过程详解</h3><p><strong>每个Mapper任务是一个java进程</strong>，它会读取HDFS中的文件，解析成很多的键值对，经过我们覆盖的map方法处理后，转换为很多的键值对再输出。整个Mapper任务的处理过程又可以分为以下几个阶段，如图所示：<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/cTWHrBBqmvhM.png" alt="Mapper执行过程"></p><p>在上图中，把Mapper任务的运行过程分为六个阶段。</p><ol><li><p>第一阶段是把输入文件按照一定的标准分片(InputSplit)，每个输入片的大小是固定的。默认情况下，输入片(InputSplit)的大小与数据块(Block)的大小是相同的。如果数据块(Block)的大小是默认值64MB，输入文件有两个，一个是32MB，一个是72MB。那么小的文件是一个输入片，大文件会分为两个数据块，那么是两个输入片。一共产生三个输入片。每一个输入片由一个Mapper进程处理。这里的三个输入片，会有三个Mapper进程处理。</p></li><li><p>第二阶段是对输入片中的记录按照一定的规则解析成键值对。有个默认规则是把每一行文本内容解析成键值对。“键”是每一行的起始位置(单位是字节)，“值”是本行的文本内容。</p></li><li><p>第三阶段是调用Mapper类中的map方法。第二阶段中解析出来的每一个键值对，调用一次map方法。如果有1000个键值对，就会调用1000次map方法。每一次调用map方法会输出零个或者多个键值对。</p></li><li><p>第四阶段是按照一定的规则对第三阶段输出的键值对进行分区。比较是基于键进行的。比如我们的键表示省份(如北京、上海、山东等)，那么就可以按照不同省份进行分区，同一个省份的键值对划分到一个区中。默认是只有一个区。分区的数量就是Reducer任务运行的数量。默认只有一个Reducer任务。</p></li><li><p>第五阶段是对每个分区中的键值对进行排序。首先，按照键进行排序，对于键相同的键值对，按照值进行排序。比如三个键值对&lt;2,2&gt;、&lt;1,3&gt;、&lt;2,1&gt;，键和值分别是整数。那么排序后的结果是&lt;1,3&gt;、&lt;2,1&gt;、&lt;2,2&gt;。如果有第六阶段，那么进入第六阶段；如果没有，直接输出到本地的linux文件中。</p></li><li><p>第六阶段是对数据进行归约处理，也就是reduce处理。键相等的键值对会调用一次reduce方法。经过这一阶段，数据量会减少。归约后的数据输出到本地的linxu文件中。本阶段默认是没有的，需要用户自己增加这一阶段的代码。</p></li></ol><h3 id="Reducer任务的执行过程详解"><a href="#Reducer任务的执行过程详解" class="headerlink" title="Reducer任务的执行过程详解"></a>Reducer任务的执行过程详解</h3><p><strong>每个Reducer任务是一个java进程</strong>。Reducer任务接收Mapper任务的输出，归约处理后写入到HDFS中，可以分为如下图所示的几个阶段。<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/UPvIszDbzRJW.png" alt="Reducer执行过程"></p><ol><li><p>第一阶段是Reducer任务会主动从Mapper任务复制其输出的键值对。Mapper任务可能会有很多，因此Reducer会复制多个Mapper的输出。</p></li><li><p>第二阶段是把复制到Reducer本地数据，全部进行合并，即把分散的数据合并成一个大的数据。再对合并后的数据排序。</p></li><li><p>第三阶段是对排序后的键值对调用reduce方法。键相等的键值对调用一次reduce方法，每次调用会产生零个或者多个键值对。最后把这些输出的键值对写入到HDFS文件中。</p></li></ol><p>在整个MapReduce程序的开发过程中，我们最大的工作量是覆盖map函数和覆盖reduce函数。</p><h3 id="键值对的编号"><a href="#键值对的编号" class="headerlink" title="键值对的编号"></a>键值对的编号</h3><p>在对Mapper任务、Reducer任务的分析过程中，会看到很多阶段都出现了键值对，读者容易混淆，所以这里对键值对进行编号，方便大家理解键值对的变化情况，如下图所示。<br><img src="http://pn4itjib1.bkt.clouddn.com/blog/20190218/QXkSATq7bUWL.png" alt="键值对"></p><p>在上图中，对于Mapper任务输入的键值对，定义为key1和value1。在map方法中处理后，输出的键值对，定义为key2和value2。reduce方法接收key2和value2，处理后，输出key3和value3。在下文讨论键值对时，可能把key1和value1简写为&lt;k1,v1&gt;，key2和value2简写为&lt;k2,v2&gt;，key3和value3简写为&lt;k3,v3&gt;。</p><p>以上内容来自：<a href="https://my.oschina.net/itblog/blog/275294" target="_blank" rel="noopener">Hadoop MapReduce执行过程详解（带hadoop例子）</a></p>]]></content>
    
    <summary type="html">
    
      MapReduce运行的时候，会通过Mapper运行的任务读取HDFS中的数据文件，然后调用自己的方法，处理数据，最后输出。Reducer任务会接收Mapper任务输出的数据，作为自己的输入数据，调用自己的方法，最后输出到HDFS的文件中。
    
    </summary>
    
      <category term="Hadoop" scheme="https://jordenbruce.com/categories/Hadoop/"/>
    
    
      <category term="mapreduce" scheme="https://jordenbruce.com/tags/mapreduce/"/>
    
  </entry>
  
</feed>
